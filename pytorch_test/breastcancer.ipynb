{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is to utilised transfer learning to train a model on a dataset to classify medical image data on breast cancer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.io as io\n",
    "import time\n",
    "import copy\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root directory\n",
    "root_dir = '/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/data/breatcancer_data/archive'\n",
    "id_dir = os.listdir(root_dir)\n",
    "label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "sample_dir = os.listdir(os.path.join(root_dir,id_dir[0],label_dir[0]))\n",
    "num_classes = len(label_dir)\n",
    "\n",
    "# create transform for data augmentation: normalize, and convert to tensor\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.5, 0.5, 0.5])\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize([50,50]),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "# define hyperparameters\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "random_seed = 42\n",
    "shuffle_dataset = True\n",
    "validation_split = 0.2\n",
    "\n",
    "#show image\n",
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset class for breast cancer data\n",
    "\n",
    "class breastcancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # get root directory\n",
    "        self.root_dir = root_dir\n",
    "        # get transform\n",
    "        self.transform = transform\n",
    "        # get list of label from directory under root_dir\n",
    "        id_dir = os.listdir(root_dir)\n",
    "        label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "        self.data = pd.DataFrame(columns=['id','label','image_name'])\n",
    "        \n",
    "        # loop through id in id_dir and label in label_dir to get image name and label\n",
    "        for id in id_dir:\n",
    "            for label in label_dir:\n",
    "                tempdata = pd.DataFrame(columns=['id','label','image_name'])\n",
    "                tempdata['image_name'] = os.listdir(os.path.join(root_dir, id, label))\n",
    "                tempdata['id'] = id\n",
    "                tempdata['label'] = label\n",
    "                self.data = pd.concat([self.data, tempdata],ignore_index = True, axis = 0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get image name and label from dataframe\n",
    "        img_name = os.path.join(self.root_dir,self.data.iloc[idx, 0],self.data.iloc[idx, 1],self.data.iloc[idx, 2])\n",
    "        image = io.imread(img_name)\n",
    "        label = torch.tensor(int(self.data.iloc[idx, 1]))\n",
    "                \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556\n",
      "Step [100/556]\n",
      "Step [200/556]\n",
      "Step [300/556]\n",
      "Step [400/556]\n",
      "Step [500/556]\n",
      "Finish with: 18.06663203239441 second, num_workers=2\n",
      "556\n",
      "Step [100/556]\n",
      "Step [200/556]\n",
      "Step [300/556]\n",
      "Step [400/556]\n",
      "Step [500/556]\n",
      "Finish with: 10.651078939437866 second, num_workers=4\n",
      "556\n",
      "Step [100/556]\n",
      "Step [200/556]\n",
      "Step [300/556]\n",
      "Step [400/556]\n",
      "Step [500/556]\n",
      "Finish with: 8.501567840576172 second, num_workers=6\n",
      "556\n",
      "Step [100/556]\n",
      "Step [200/556]\n",
      "Step [300/556]\n",
      "Step [400/556]\n",
      "Step [500/556]\n",
      "Finish with: 7.7006213665008545 second, num_workers=8\n",
      "556\n",
      "Step [100/556]\n",
      "Step [200/556]\n",
      "Step [300/556]\n",
      "Step [400/556]\n",
      "Step [500/556]\n",
      "Finish with: 7.516961574554443 second, num_workers=10\n",
      "Lowest time taken: 7.516961574554443 second, num_workers=10\n"
     ]
    }
   ],
   "source": [
    "#check lowest time to load data for given num_workers\n",
    "lowesttime = 999999999\n",
    "num_workers_lowest = 0\n",
    "\n",
    "for num_workers in range (2, mp.cpu_count(),2):\n",
    "    testloader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "    n_total_steps = len(testloader)\n",
    "    print(n_total_steps)\n",
    "    start = time.time()\n",
    "    for epoch in range(1,2):\n",
    "        for i, data in enumerate(testloader,0):\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Step [{}/{}]'.format(i+1, n_total_steps))\n",
    "            pass\n",
    "    end = time.time()\n",
    "    percent = (i/n_total_steps)*100\n",
    "    timetaken = end - start\n",
    "    print(\"Finish with: {} second, num_workers={}\".format(timetaken,num_workers))\n",
    "    if timetaken < lowesttime:\n",
    "        lowesttime = timetaken\n",
    "        num_workers_lowest = num_workers\n",
    "\n",
    "print(\"Lowest time taken: {} second, num_workers={}\".format(lowesttime,num_workers_lowest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset object\n",
    "dataset = breastcancerDataset(root_dir,data_transforms)\n",
    "\n",
    "# create data indices for training and validation splits\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# create samplers for training and validation splits\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers_lowest)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, classes = next(iter(train_loader))\n",
    "#print(images.shape[2])\n",
    "#print(type(images))\n",
    "#print(images.shape)\n",
    "#imshow(torchvision.utils.make_grid(images), title=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up device to run on cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training loop function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in range(2):\n",
    "            if phase == 0:\n",
    "                # set model to train mode for training phase\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                # set model to evaluate mode for validation phase\n",
    "                model.eval()\n",
    "                dataloader = valid_loader\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over databatchs for give phase\n",
    "            n_total_steps = len(dataloader)\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # enable gradient computation when phase is train and forward pass for both phase\n",
    "                with torch.set_grad_enabled(phase == 0):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward pass only if phase is train\n",
    "                    if phase == 0:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print ('Step [{}/{}], Loss: {:.4f}'.format(i+1, n_total_steps, loss.item()))\n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model and update best_acc if phase is validation and epoch_acc is greater than best_acc\n",
    "            if phase == 1 and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Best Acc: {:.4f}'.format(best_acc))\n",
    "            # adjust learning rate using scheduler if phase is validation\n",
    "            if phase == 1:\n",
    "                print('Scheduler step')\n",
    "                scheduler.step()\n",
    "        print()\n",
    "\n",
    "    # record time to train model\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune model\n",
    "# define fine tuned model as pretrained resnet34\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# freeze all existing parameters\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#get number of input features of last layer\n",
    "num_features = model_ft.fc.in_features\n",
    "\n",
    "#replace last layer with new layer with number of classes as output\n",
    "model_ft.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# set model to current device\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# setup scheduler for learning rate decay\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Step [10/4441], Loss: 0.7802\n",
      "Step [20/4441], Loss: 0.6700\n",
      "Step [30/4441], Loss: 0.7036\n",
      "Step [40/4441], Loss: 0.5904\n",
      "Step [50/4441], Loss: 0.4753\n",
      "Step [60/4441], Loss: 0.5051\n",
      "Step [70/4441], Loss: 0.6469\n",
      "Step [80/4441], Loss: 0.6904\n",
      "Step [90/4441], Loss: 0.5431\n",
      "Step [100/4441], Loss: 0.4904\n",
      "Step [110/4441], Loss: 0.5219\n",
      "Step [120/4441], Loss: 0.4815\n",
      "Step [130/4441], Loss: 0.5168\n",
      "Step [140/4441], Loss: 0.4167\n",
      "Step [150/4441], Loss: 0.7163\n",
      "Step [160/4441], Loss: 0.4699\n",
      "Step [170/4441], Loss: 0.5446\n",
      "Step [180/4441], Loss: 0.5083\n",
      "Step [190/4441], Loss: 0.4552\n",
      "Step [200/4441], Loss: 0.3891\n",
      "Step [210/4441], Loss: 0.5768\n",
      "Step [220/4441], Loss: 0.3738\n",
      "Step [230/4441], Loss: 0.3367\n",
      "Step [240/4441], Loss: 0.3429\n",
      "Step [250/4441], Loss: 0.3893\n",
      "Step [260/4441], Loss: 0.3553\n",
      "Step [270/4441], Loss: 0.6322\n",
      "Step [280/4441], Loss: 0.3640\n",
      "Step [290/4441], Loss: 0.4238\n",
      "Step [300/4441], Loss: 0.4593\n",
      "Step [310/4441], Loss: 0.5041\n",
      "Step [320/4441], Loss: 0.5067\n",
      "Step [330/4441], Loss: 0.5533\n",
      "Step [340/4441], Loss: 0.4559\n",
      "Step [350/4441], Loss: 0.3508\n",
      "Step [360/4441], Loss: 0.5019\n",
      "Step [370/4441], Loss: 0.4891\n",
      "Step [380/4441], Loss: 0.3466\n",
      "Step [390/4441], Loss: 0.5369\n",
      "Step [400/4441], Loss: 0.4450\n",
      "Step [410/4441], Loss: 0.4228\n",
      "Step [420/4441], Loss: 0.6064\n",
      "Step [430/4441], Loss: 0.3069\n",
      "Step [440/4441], Loss: 0.4360\n",
      "Step [450/4441], Loss: 0.3816\n",
      "Step [460/4441], Loss: 0.3647\n",
      "Step [470/4441], Loss: 0.4037\n",
      "Step [480/4441], Loss: 0.3006\n",
      "Step [490/4441], Loss: 0.4587\n",
      "Step [500/4441], Loss: 0.4620\n",
      "Step [510/4441], Loss: 0.4981\n",
      "Step [520/4441], Loss: 0.4734\n",
      "Step [530/4441], Loss: 0.4166\n",
      "Step [540/4441], Loss: 0.4860\n",
      "Step [550/4441], Loss: 0.4038\n",
      "Step [560/4441], Loss: 0.3824\n",
      "Step [570/4441], Loss: 0.3615\n",
      "Step [580/4441], Loss: 0.3907\n",
      "Step [590/4441], Loss: 0.4231\n",
      "Step [600/4441], Loss: 0.5027\n",
      "Step [610/4441], Loss: 0.5185\n",
      "Step [620/4441], Loss: 0.3505\n",
      "Step [630/4441], Loss: 0.3524\n",
      "Step [640/4441], Loss: 0.5481\n",
      "Step [650/4441], Loss: 0.4973\n",
      "Step [660/4441], Loss: 0.4860\n",
      "Step [670/4441], Loss: 0.3299\n",
      "Step [680/4441], Loss: 0.7978\n",
      "Step [690/4441], Loss: 0.4149\n",
      "Step [700/4441], Loss: 0.4932\n",
      "Step [710/4441], Loss: 0.2977\n",
      "Step [720/4441], Loss: 0.5053\n",
      "Step [730/4441], Loss: 0.3301\n",
      "Step [740/4441], Loss: 0.3978\n",
      "Step [750/4441], Loss: 0.4831\n",
      "Step [760/4441], Loss: 0.4946\n",
      "Step [770/4441], Loss: 0.4564\n",
      "Step [780/4441], Loss: 0.5342\n",
      "Step [790/4441], Loss: 0.4405\n",
      "Step [800/4441], Loss: 0.3457\n",
      "Step [810/4441], Loss: 0.2942\n",
      "Step [820/4441], Loss: 0.4225\n",
      "Step [830/4441], Loss: 0.4394\n",
      "Step [840/4441], Loss: 0.4182\n",
      "Step [850/4441], Loss: 0.3798\n",
      "Step [860/4441], Loss: 0.4798\n",
      "Step [870/4441], Loss: 0.3730\n",
      "Step [880/4441], Loss: 0.3659\n",
      "Step [890/4441], Loss: 0.3741\n",
      "Step [900/4441], Loss: 0.4975\n",
      "Step [910/4441], Loss: 0.3479\n",
      "Step [920/4441], Loss: 0.5622\n",
      "Step [930/4441], Loss: 0.4883\n",
      "Step [940/4441], Loss: 0.3028\n",
      "Step [950/4441], Loss: 0.2863\n",
      "Step [960/4441], Loss: 0.3437\n",
      "Step [970/4441], Loss: 0.5000\n",
      "Step [980/4441], Loss: 0.3341\n",
      "Step [990/4441], Loss: 0.3152\n",
      "Step [1000/4441], Loss: 0.4191\n",
      "Step [1010/4441], Loss: 0.4671\n",
      "Step [1020/4441], Loss: 0.3752\n",
      "Step [1030/4441], Loss: 0.2708\n",
      "Step [1040/4441], Loss: 0.5260\n",
      "Step [1050/4441], Loss: 0.3261\n",
      "Step [1060/4441], Loss: 0.4247\n",
      "Step [1070/4441], Loss: 0.5211\n",
      "Step [1080/4441], Loss: 0.2562\n",
      "Step [1090/4441], Loss: 0.5325\n",
      "Step [1100/4441], Loss: 0.2344\n",
      "Step [1110/4441], Loss: 0.2408\n",
      "Step [1120/4441], Loss: 0.4684\n",
      "Step [1130/4441], Loss: 0.4541\n",
      "Step [1140/4441], Loss: 0.3927\n",
      "Step [1150/4441], Loss: 0.4946\n",
      "Step [1160/4441], Loss: 0.4998\n",
      "Step [1170/4441], Loss: 0.4243\n",
      "Step [1180/4441], Loss: 0.4875\n",
      "Step [1190/4441], Loss: 0.6327\n",
      "Step [1200/4441], Loss: 0.5291\n",
      "Step [1210/4441], Loss: 0.4318\n",
      "Step [1220/4441], Loss: 0.3181\n",
      "Step [1230/4441], Loss: 0.5263\n",
      "Step [1240/4441], Loss: 0.5178\n",
      "Step [1250/4441], Loss: 0.4250\n",
      "Step [1260/4441], Loss: 0.4032\n",
      "Step [1270/4441], Loss: 0.3763\n",
      "Step [1280/4441], Loss: 0.3145\n",
      "Step [1290/4441], Loss: 0.4032\n",
      "Step [1300/4441], Loss: 0.3891\n",
      "Step [1310/4441], Loss: 0.5488\n",
      "Step [1320/4441], Loss: 0.2819\n",
      "Step [1330/4441], Loss: 0.5480\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000009?line=0'>1</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer, step_lr_scheduler, num_epochs\u001b[39m=\u001b[39;49mnum_epochs)\n",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb Cell 7'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=22'>23</a>\u001b[0m \u001b[39m# Iterate over databatchs for give phase\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=23'>24</a>\u001b[0m n_total_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=25'>26</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=26'>27</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1186\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1182'>1183</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1184'>1185</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1185'>1186</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1186'>1187</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1187'>1188</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1188'>1189</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1152\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1147'>1148</a>\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1148'>1149</a>\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1149'>1150</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1150'>1151</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1151'>1152</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1152'>1153</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1153'>1154</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:990\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=976'>977</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=977'>978</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=978'>979</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=986'>987</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=987'>988</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=988'>989</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=989'>990</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=990'>991</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=991'>992</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=992'>993</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=993'>994</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=994'>995</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=105'>106</a>\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=107'>108</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=255'>256</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=422'>423</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=423'>424</a>\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=424'>425</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=927'>928</a>\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=929'>930</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=930'>931</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=931'>932</a>\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=932'>933</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer, step_lr_scheduler, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b21db2b3bfa18fa7fb00a95d42ac639431518c9b93a669b09d22217e9d3cd63e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
