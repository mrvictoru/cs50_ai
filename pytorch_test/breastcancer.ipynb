{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is to utilised transfer learning to train a model on a dataset to classify medical image data on breast cancer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.io as io\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root directory\n",
    "root_dir = '/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/data/breatcancer_data/archive'\n",
    "id_dir = os.listdir(root_dir)\n",
    "label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "sample_dir = os.listdir(os.path.join(root_dir,id_dir[0],label_dir[0]))\n",
    "\n",
    "# create transform for data augmentation: normalize, and convert to tensor\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.5, 0.5, 0.5])\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "# define hyperparameters\n",
    "batch_size = 10\n",
    "num_epochs = 25\n",
    "random_seed = 42\n",
    "shuffle_dataset = True\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset class for breast cancer data\n",
    "\n",
    "class breastcancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # get root directory\n",
    "        self.root_dir = root_dir\n",
    "        # get transform\n",
    "        self.transform = transform\n",
    "        # get list of label from directory under root_dir\n",
    "        id_dir = os.listdir(root_dir)\n",
    "        label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "        self.data = pd.DataFrame(columns=['id','label','image_name'])\n",
    "        \n",
    "        # loop through id in id_dir and label in label_dir to get image name and label\n",
    "        for id in id_dir:\n",
    "            for label in label_dir:\n",
    "                tempdata = pd.DataFrame(columns=['id','label','image_name'])\n",
    "                tempdata['image_name'] = os.listdir(os.path.join(root_dir, id, label))\n",
    "                tempdata['id'] = id\n",
    "                tempdata['label'] = label\n",
    "                self.data = pd.concat([self.data, tempdata],ignore_index = True, axis = 0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get image name and label from dataframe\n",
    "        id = self.data.iloc[idx,0]\n",
    "        img_name = os.path.join(self.root_dir,self.data.iloc[idx, 0],self.data.iloc[idx, 1],self.data.iloc[idx, 2])\n",
    "        image = io.imread(img_name)\n",
    "        image = image.reshape(3,50,50)\n",
    "        label = torch.tensor(int(self.data.iloc[idx, 1]))\n",
    "                \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return id,image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset object\n",
    "dataset = breastcancerDataset(root_dir)\n",
    "\n",
    "# create data indices for training and validation splits\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# create samplers for training and validation splits\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#setting up device to run on cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training loop function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in range(2):\n",
    "            if phase == 0:\n",
    "                # set model to train mode for training phase\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                # set model to evaluate mode for validation phase\n",
    "                model.eval()\n",
    "                dataloader = valid_loader\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over databatchs for give phase\n",
    "            \n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # enable gradient computation when phase is train and forward pass for both phase\n",
    "                with torch.set_grad_enabled(phase == 0):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward pass only if phase is train\n",
    "                    if phase == 0:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model and update best_acc if phase is validation and epoch_acc is greater than best_acc\n",
    "            if phase == 1 and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Best Acc: {:.4f}'.format(best_acc))\n",
    "            # adjust learning rate using scheduler if phase is validation\n",
    "            if phase == 1:\n",
    "                print('Scheduler step')\n",
    "                scheduler.step()\n",
    "        print()\n",
    "\n",
    "    # record time to train model\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b21db2b3bfa18fa7fb00a95d42ac639431518c9b93a669b09d22217e9d3cd63e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
