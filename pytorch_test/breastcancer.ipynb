{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is to utilised transfer learning to train a model on a dataset to classify medical image data on breast cancer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.io as io\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root directory\n",
    "root_dir = '/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/data/breatcancer_data/archive'\n",
    "id_dir = os.listdir(root_dir)\n",
    "label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "\n",
    "# create transform for data augmentation: normalize, and convert to tensor\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.5, 0.5, 0.5])\n",
    "data_transforms = {\n",
    "    label_dir[0]: transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(), #add randomness to data augmentation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    label_dir[1]: transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "# define hyperparameters\n",
    "batch_size = 100\n",
    "num_epochs = 25\n",
    "random_seed = 42\n",
    "shuffle_dataset = True\n",
    "validation_split = 0.2\n",
    "\n",
    "#show image\n",
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10253', '10254', '10255', '10256', '10257', '10258', '10259', '10260', '10261', '10262', '10264', '10268', '10269', '10272', '10273', '10274', '10275', '10276', '10277', '10278', '10282', '10285', '10286', '10288', '10290', '10291', '10292', '10293', '10295', '10299', '10300', '10301', '10302', '10303', '10304', '10305', '10306', '10307', '10308', '12241', '12626', '12748', '12749', '12750', '12751', '12752', '12810', '12811', '12817', '12818', '12819', '12820', '12821', '12822', '12823', '12824', '12826', '12867', '12868', '12869', '12871', '12872', '12873', '12875', '12876', '12877', '12878', '12879', '12880', '12881', '12882', '12883', '12884', '12886', '12890', '12891', '12892', '12893', '12894', '12895', '12897', '12898', '12900', '12901', '12905', '12906', '12907', '12908', '12909', '12910', '12911', '12929', '12930', '12931', '12932', '12933', '12934', '12935', '12947', '12948', '10279', '12242', '12870', '12896', '12949', '13461', '14155', '15512', '16550', '8951', '9077', '9254', '12951', '12954', '12955', '13018', '13019', '13020', '13021', '13022', '13023', '13024', '13025', '13106', '13400', '13401', '13402', '13403', '13404', '13458', '13459', '13460', '13462', '13591', '13613', '13616', '13617', '13666', '13687', '13688', '13689', '13691', '13692', '13693', '13694', '13916', '14078', '14079', '14081', '14082', '14153', '14154', '14156', '14157', '14188', '14189', '14190', '14191', '14192', '14209', '14210', '14211', '14212', '14213', '14304', '14305', '14306', '14321', '15471', '15472', '15473', '15510', '15513', '15514', '15515', '15516', '15632', '15633', '15634', '15839', '15840', '15902', '15903', '16014', '16085', '16165', '16166', '16167', '16531', '16532', '16533', '16534', '16551', '16552', '16553', '16554', '16555', '16568', '16569', '16570', '16895', '16896', '8863', '8864', '8865', '8867', '8913', '8914', '8916', '8917', '8918', '8950', '8955', '8956', '8957', '8959', '8974', '8975', '8980', '8984', '9022', '9023', '9029', '9035', '9036', '9037', '9041', '9043', '9044', '9073', '9075', '9076', '9078', '9081', '9083', '9123', '9124', '9125', '9126', '9135', '9173', '9174', '9175', '9176', '9177', '9178', '9181', '9225', '9226', '9227', '9228', '9250', '9255', '9256', '9257', '9258', '9259', '9260', '9261', '9262', '9265', '9266', '9267', '9290', '9291', '9319', '9320', '9321', '9322', '9323', '9324', '9325', '9344', '9345', '9346', '9347', '9381', '9382', '9383']\n",
      "['0', '1']\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/data/breatcancer_data/archive/10253/0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_dir = '/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/data/breatcancer_data/archive'\n",
    "id_dir = os.listdir(root_dir)\n",
    "label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "print(id_dir)\n",
    "print(label_dir)\n",
    "for id in id_dir:\n",
    "    for label in label_dir:\n",
    "\n",
    "        print(type(id))\n",
    "        print(type(label))\n",
    "        print(os.path.join(root_dir,id,label))\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset class for breast cancer data\n",
    "\n",
    "class breastcancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # get root directory\n",
    "        self.root_dir = root_dir\n",
    "        # get transform\n",
    "        self.transform = transform\n",
    "        # get list of label from directory under root_dir\n",
    "        id_dir = os.listdir(root_dir)\n",
    "        label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "        self.data = pd.DataFrame(columns=['id','label','image_name'])\n",
    "        \n",
    "        # loop through id in id_dir and label in label_dir to get image name and label\n",
    "        for id in id_dir:\n",
    "            for label in label_dir:\n",
    "                tempdata = pd.DataFrame(columns=['id','label','image_name'])\n",
    "                tempdata['image_name'] = os.listdir(os.path.join(root_dir, id, label))\n",
    "                tempdata['id'] = id\n",
    "                tempdata['label'] = label\n",
    "                self.data = pd.concat([self.data, tempdata],ignore_index = True, axis = 0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get image name and label from dataframe\n",
    "        id = self.data.iloc[idx,0]\n",
    "        img_name = os.path.join(self.root_dir,self.data.iloc[idx, 0],self.data.iloc[idx, 1],self.data.iloc[idx, 2])\n",
    "        image = io.imread(img_name)\n",
    "        label = torch.tensor(int(self.data.iloc[idx, 1]))\n",
    "                \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return id,image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset object\n",
    "dataset = breastcancerDataset(root_dir)\n",
    "\n",
    "# create data indices for training and validation splits\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# create samplers for training and validation splits\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2221\n",
      "277524\n",
      "99.963980189104\n",
      "222020\n"
     ]
    }
   ],
   "source": [
    "# check random img from trainset\n",
    "dataiter = iter(train_loader)\n",
    "print(len(dataiter))\n",
    "print(dataset_size)\n",
    "print(len(train_indices)/len(dataiter))\n",
    "print(len(train_indices))\n",
    "#images, labels = dataiter.next()\n",
    "#print(labels)\n",
    "\n",
    "#show images\n",
    "#imshow(torchvision.utils.make_grid(images))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b21db2b3bfa18fa7fb00a95d42ac639431518c9b93a669b09d22217e9d3cd63e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
