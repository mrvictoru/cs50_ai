{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is to utilised transfer learning to train a model on a dataset to classify medical image data on breast cancer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import time\n",
    "import copy\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root directory\n",
    "root_dir = '/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/data/breatcancer_data/archive'\n",
    "id_dir = os.listdir(root_dir)\n",
    "label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "sample_dir = os.listdir(os.path.join(root_dir,id_dir[0],label_dir[0]))\n",
    "num_classes = len(label_dir)\n",
    "\n",
    "# create transform for data augmentation: normalize, and convert to tensor\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.5, 0.5, 0.5])\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize([50,50]),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "# define hyperparameters\n",
    "batch_size = 100\n",
    "num_epochs = 3\n",
    "random_seed = 42\n",
    "shuffle_dataset = True\n",
    "validation_split = 0.2\n",
    "\n",
    "#show image\n",
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset class for breast cancer data\n",
    "\n",
    "class breastcancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # get root directory\n",
    "        self.root_dir = root_dir\n",
    "        # get transform\n",
    "        self.transform = transform\n",
    "        # get list of label from directory under root_dir\n",
    "        id_dir = os.listdir(root_dir)\n",
    "        label_dir = os.listdir(os.path.join(root_dir,id_dir[0]))\n",
    "        self.data = pd.DataFrame(columns=['id','label','image_name'])\n",
    "        \n",
    "        # loop through id in id_dir and label in label_dir to get image name and label\n",
    "        for id in id_dir:\n",
    "            for label in label_dir:\n",
    "                tempdata = pd.DataFrame(columns=['id','label','image_name'])\n",
    "                tempdata['image_name'] = os.listdir(os.path.join(root_dir, id, label))\n",
    "                tempdata['id'] = id\n",
    "                tempdata['label'] = label\n",
    "                self.data = pd.concat([self.data, tempdata],ignore_index = True, axis = 0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get image name and label from dataframe\n",
    "        img_name = os.path.join(self.root_dir,self.data.iloc[idx, 0],self.data.iloc[idx, 1],self.data.iloc[idx, 2])\n",
    "        image = read_image(img_name)\n",
    "        label = torch.tensor(int(self.data.iloc[idx, 1]))\n",
    "                \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277524\n"
     ]
    }
   ],
   "source": [
    "# create dataset object\n",
    "dataset = breastcancerDataset(root_dir,data_transforms)\n",
    "\n",
    "# create data indices for training and validation splits\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# create samplers for training and validation splits\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of worker: 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_148736/2020481451.py\", line 33, in __getitem__\n    image = self.transform(image)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 98, in __call__\n    return F.to_tensor(pic)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\", line 114, in to_tensor\n    raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\nTypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000003?line=8'>9</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000003?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(testloader,\u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000003?line=11'>12</a>\u001b[0m         \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000003?line=12'>13</a>\u001b[0m             \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mStep [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, n_total_steps))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1203\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1200'>1201</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1201'>1202</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1202'>1203</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1229\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1226'>1227</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1227'>1228</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1228'>1229</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1229'>1230</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/_utils.py?line=429'>430</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/_utils.py?line=430'>431</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/_utils.py?line=431'>432</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/_utils.py?line=432'>433</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/_utils.py?line=433'>434</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_148736/2020481451.py\", line 33, in __getitem__\n    image = self.transform(image)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 98, in __call__\n    return F.to_tensor(pic)\n  File \"/home/victoru/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\", line 114, in to_tensor\n    raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\nTypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#check lowest time to load data for given num_workers\n",
    "lowesttime = 999999999\n",
    "num_workers_lowest = 0\n",
    "\n",
    "for num_workers in range (2, mp.cpu_count(),2):\n",
    "    testloader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "    print('number of worker: {}'.format(num_workers))\n",
    "    n_total_steps = len(testloader)\n",
    "    start = time.time()\n",
    "    for epoch in range(1,2):\n",
    "        for i, data in enumerate(testloader,0):\n",
    "            if (i+1) % 20 == 0:\n",
    "                print ('Step [{}/{}]'.format(i+1, n_total_steps))\n",
    "            if i/n_total_steps > 0.4:\n",
    "                print(\"40 percent of data loaded\")\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "    end = time.time()\n",
    "    percent = (i/n_total_steps)*100\n",
    "    timetaken = end - start\n",
    "    print(\"Finish with: {} second, num_workers={}\".format(timetaken,num_workers))\n",
    "    if timetaken < lowesttime:\n",
    "        lowesttime = timetaken\n",
    "        num_workers_lowest = num_workers\n",
    "\n",
    "print(\"Lowest time taken: {} second, num_workers={}\".format(lowesttime,num_workers_lowest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers_lowest)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, classes = next(iter(train_loader))\n",
    "#print(images.shape[2])\n",
    "#print(type(images))\n",
    "#print(images.shape)\n",
    "#imshow(torchvision.utils.make_grid(images), title=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up device to run on cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training loop function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in range(2):\n",
    "            if phase == 0:\n",
    "                # set model to train mode for training phase\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                # set model to evaluate mode for validation phase\n",
    "                model.eval()\n",
    "                dataloader = valid_loader\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over databatchs for give phase\n",
    "            n_total_steps = len(dataloader)\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # enable gradient computation when phase is train and forward pass for both phase\n",
    "                with torch.set_grad_enabled(phase == 0):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward pass only if phase is train\n",
    "                    if phase == 0:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print ('Step [{}/{}], Loss: {:.4f}'.format(i+1, n_total_steps, loss.item()))\n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model and update best_acc if phase is validation and epoch_acc is greater than best_acc\n",
    "            if phase == 1 and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Best Acc: {:.4f}'.format(best_acc))\n",
    "            # adjust learning rate using scheduler if phase is validation\n",
    "            if phase == 1:\n",
    "                print('Scheduler step')\n",
    "                scheduler.step()\n",
    "        print()\n",
    "\n",
    "    # record time to train model\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune model\n",
    "# define fine tuned model as pretrained resnet34\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# freeze all existing parameters\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#get number of input features of last layer\n",
    "num_features = model_ft.fc.in_features\n",
    "\n",
    "#replace last layer with new layer with number of classes as output\n",
    "model_ft.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# set model to current device\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# setup scheduler for learning rate decay\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Step [100/2221], Loss: 0.4503\n",
      "Step [200/2221], Loss: 0.5397\n",
      "Step [300/2221], Loss: 0.4428\n",
      "Step [400/2221], Loss: 0.4109\n",
      "Step [500/2221], Loss: 0.4071\n",
      "Step [600/2221], Loss: 0.4730\n",
      "Step [700/2221], Loss: 0.5564\n",
      "Step [800/2221], Loss: 0.4827\n",
      "Step [900/2221], Loss: 0.3717\n",
      "Step [1000/2221], Loss: 0.3949\n",
      "Step [1100/2221], Loss: 0.4035\n",
      "Step [1200/2221], Loss: 0.3479\n",
      "Step [1300/2221], Loss: 0.4144\n",
      "Step [1400/2221], Loss: 0.4595\n",
      "Step [1500/2221], Loss: 0.4589\n",
      "Step [1600/2221], Loss: 0.4287\n",
      "Step [1700/2221], Loss: 0.3485\n",
      "Step [1800/2221], Loss: 0.3703\n",
      "Step [1900/2221], Loss: 0.3214\n",
      "Step [2000/2221], Loss: 0.4693\n",
      "Step [2100/2221], Loss: 0.5643\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000009?line=0'>1</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer, step_lr_scheduler, num_epochs\u001b[39m=\u001b[39;49mnum_epochs)\n",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=22'>23</a>\u001b[0m \u001b[39m# Iterate over databatchs for give phase\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=23'>24</a>\u001b[0m n_total_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=25'>26</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/breastcancer.ipynb#ch0000007?line=26'>27</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1186\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1182'>1183</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1184'>1185</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1185'>1186</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1186'>1187</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1187'>1188</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1188'>1189</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1152\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1147'>1148</a>\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1148'>1149</a>\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1149'>1150</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1150'>1151</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1151'>1152</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1152'>1153</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1153'>1154</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:990\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=976'>977</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=977'>978</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=978'>979</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=986'>987</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=987'>988</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=988'>989</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=989'>990</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=990'>991</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=991'>992</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=992'>993</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=993'>994</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=994'>995</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=105'>106</a>\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=107'>108</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/queues.py?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=255'>256</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=422'>423</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=423'>424</a>\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=424'>425</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=927'>928</a>\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=929'>930</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=930'>931</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=931'>932</a>\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/multiprocessing/connection.py?line=932'>933</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/victoru/anaconda3/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer, step_lr_scheduler, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b21db2b3bfa18fa7fb00a95d42ac639431518c9b93a669b09d22217e9d3cd63e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
