{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This notebook uses Long Short-Term Memory (LSTM) to predict the closing stock price of a corporation using the past 60 day stock price.\n",
    "\n",
    "# Import the libraries\n",
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Get cuda device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the past year stock price\n",
    "# today's date\n",
    "today = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
    "# 5 year ago\n",
    "start = pd.to_datetime('today') - pd.DateOffset(years=5)\n",
    "df = web.DataReader('AAPL', data_source='yahoo', start=start, end=today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the 'Close' column\n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataarray = data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloading method\n",
    "def dataloading(data, seq_len = 60):\n",
    "    sc = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = sc.fit_transform(data)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(scaled_data)-seq_len-1):\n",
    "        _x = scaled_data[i:(i+seq_len)]\n",
    "\n",
    "        _y = scaled_data[i+seq_len]\n",
    "        x.append(_x)\n",
    "\n",
    "        y.append(_y)\n",
    "\n",
    "    # Get the number of rows to train the model on\n",
    "    training_data_len = math.ceil( len(dataarray) * .8 )\n",
    "    test_data_len = len(dataarray) - training_data_len\n",
    "\n",
    "    dataX = Variable(torch.Tensor(np.array(x)))\n",
    "    dataY = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "    trainX = Variable(torch.Tensor(np.array(x[0:training_data_len])))\n",
    "    trainY = Variable(torch.Tensor(np.array(y[0:training_data_len])))\n",
    "\n",
    "    testX = dataX[training_data_len:]\n",
    "    testY = dataY[training_data_len:]\n",
    "\n",
    "    return trainX, trainY, testX, testY, dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trainX, trainY, testX, testY, dataX, dataY = dataloading(dataarray)\n",
    "\n",
    "# move data to device\n",
    "trainX = trainX.to(device)\n",
    "trainY = trainY.to(device)\n",
    "testX = testX.to(device)\n",
    "testY = testY.to(device)\n",
    "dataX = dataX.to(device)\n",
    "dataY = dataY.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=1, num_classes=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training method\n",
    "def train(model, trainX, trainY, num_epochs=100, learning_rate=0.001):\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(trainX)\n",
    "        loss = criterion(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                .format(epoch+1, num_epochs, loss.item()))\n",
    "    \n",
    "    return model\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0934\n",
      "Epoch [20/100], Loss: 0.0588\n",
      "Epoch [30/100], Loss: 0.0454\n",
      "Epoch [40/100], Loss: 0.0327\n",
      "Epoch [50/100], Loss: 0.0117\n",
      "Epoch [60/100], Loss: 0.0066\n",
      "Epoch [70/100], Loss: 0.0034\n",
      "Epoch [80/100], Loss: 0.0027\n",
      "Epoch [90/100], Loss: 0.0019\n",
      "Epoch [100/100], Loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model = LSTM()\n",
    "model = train(model.to(device), trainX, trainY, num_epochs=100, learning_rate=0.001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
