{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# this notebook will use a basic GPT based decision transformer in offline reinforcement learning setting to create bot for trading stock\n",
    "# get cuda device\n",
    "# import libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cust_transf import DecisionTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-fee53e086325bcc9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets.load import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "data = load_dataset(\"json\", data_files = full_filenames[0], field = 'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.load import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utility function to compute the discounted cumulative sum of a vector\n",
    "def discount_cumsum(x, gamma):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "    return disc_cumsum\n",
    "\n",
    "def compute_rtg(data, gamma, rtg_scale):\n",
    "    rtg = []\n",
    "    for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n",
    "        rtg.append(reward)\n",
    "    return rtg\n",
    "\n",
    "# define a custom dataset class which loads the data, modifies the reward to be the discounted cumulative sum and apply trajectory masking\n",
    "class CustomTrajDataset(Dataset):\n",
    "    def __init__(self, file_name, context_len, gamma, rtg_scale):\n",
    "        self.gamma = gamma\n",
    "        self.context_len = context_len\n",
    "\n",
    "        self.data = load_dataset(\"json\", data_files = file_name, field = 'data')['train']\n",
    "\n",
    "        self.data = self.data.with_format('pandas')\n",
    "        #min_len = 10**6\n",
    "\n",
    "        # calculate mean and std of states\n",
    "        states = []\n",
    "\n",
    "        for traj in self.data['state']:\n",
    "            states.append(traj)\n",
    "            #if len(traj) < min_len:\n",
    "            #    min_len = len(traj)\n",
    "        states = np.concatenate(states, axis=0)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "        # calculate rtg\n",
    "        self.rtg = pd.Series(compute_rtg(self.data, gamma, rtg_scale))\n",
    "\n",
    "        # get the len of the dataset\n",
    "        self.stateshape = len(self.data['state'])\n",
    "\n",
    "\n",
    "    def get_state_stats(self):\n",
    "        return self.state_mean, self.state_std        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.stateshape\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "\n",
    "            state = np.stack(self.data['state'][idx])\n",
    "            action = np.stack(self.data['action'][idx])\n",
    "            rtg = self.rtg[idx]\n",
    "        except IndexError:\n",
    "            # handle index out of range error\n",
    "            raise IndexError(f\"Index {idx} out of range for dataset with length {len(self.data['state'])}\")\n",
    "\n",
    "\n",
    "        data_len = state.shape[0]\n",
    "        \n",
    "        if data_len > self.context_len:\n",
    "            # sample random start index\n",
    "            start_idx = np.random.randint(0, data_len - self.context_len)\n",
    "            # slice the data and convert to torch\n",
    "            state = torch.from_numpy(state[start_idx:start_idx+self.context_len])\n",
    "            action = torch.from_numpy(action[start_idx:start_idx+self.context_len])\n",
    "            rtg = torch.from_numpy(rtg[start_idx:start_idx+self.context_len])\n",
    "            timesteps = torch.arange(start=start_idx, end=start_idx + self.context_len, step=1)\n",
    "            # trajectory mask\n",
    "            mask = torch.ones(self.context_len, dtype=torch.long)\n",
    "        else:\n",
    "            padding_len = self.context_len - data_len\n",
    "\n",
    "            # pad the data with zeros\n",
    "            state = torch.from_numpy(state)\n",
    "            state = torch.cat([state, torch.zeros((padding_len, *state.shape[1:]))], dim=0)\n",
    "\n",
    "            action = torch.from_numpy(action)\n",
    "            action = torch.cat([action, torch.zeros((padding_len, *action.shape[1:]))], dim=0)\n",
    "\n",
    "            rtg = torch.from_numpy(rtg)\n",
    "            rtg = torch.cat([rtg, torch.zeros((padding_len, *rtg.shape[1:]))], dim=0)\n",
    "\n",
    "            timesteps = torch.arange(start=0, end=self.context_len, step=1)\n",
    "\n",
    "            # trajectory mask\n",
    "            mask = torch.cat([torch.ones(data_len, dtype=torch.long), torch.zeros(padding_len, dtype=torch.long)], dim=0)\n",
    "\n",
    "        \"\"\"\n",
    "        Exepected output type and shape\n",
    "        state type:  torch.float32\n",
    "        actions type:  torch.float32\n",
    "        rtg type:  torch.float32\n",
    "        timestep type:  torch.int64\n",
    "        traj_mask type:  torch.int64\n",
    "        shape state: torch.Size([32, 30, 13])\n",
    "        shape rtg: torch.Size([32, 30, 1])\n",
    "        shape timestep: torch.Size([32, 30])\n",
    "        shape actions: torch.Size([32, 30, 2])\n",
    "        \"\"\"\n",
    "        \n",
    "        return state.float(), action.float(), rtg.unsqueeze(-1), timesteps, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-fee53e086325bcc9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 894.50it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_2555_2015-01-01_1d_random_replaybuffer.json has 500 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-0d2b6431758d253c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1164.44it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_14_1_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-c931b78b82e2a521/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 553.56it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_2_1d_a2c_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-a7fb97aa0b2d2c17/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1169.96it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_2_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-e3558f3f5b1e1a9f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1233.26it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_3_1d_a2c_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-5650ad8da88f517f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1209.08it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_3_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-f0f6506387ff2ddb/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1063.73it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_3_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-a3af101adcd158b1/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1016.80it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_168_4_1d_a2c_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-1391ec1e9d77eb5a/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 876.37it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_168_4_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-ad2892aa847ed6ed/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1257.66it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_168_4_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-111410c52e68511e/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1096.26it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_25_2_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-7494b394211bc8ce/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_326_1_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-f82cdf55698959cf/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1230.72it/s]\n",
      "/tmp/ipykernel_6934/4280996087.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for reward in data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), gamma)/rtg_scale):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_504_1_1d_a2c_replaybuffer.json has 200 trajectories\n",
      "combined_dataset has 2900 trajectories\n"
     ]
    }
   ],
   "source": [
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "# create datasets and store in list from the list of filenames \n",
    "context_len = 30\n",
    "rtg_scale = 1e4\n",
    "gamma = 0.8\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for name in full_filenames:\n",
    "    dataset = CustomTrajDataset(name, context_len, gamma, rtg_scale)\n",
    "    print(f\"{name} has {len(dataset)} trajectories\")\n",
    "    datasets.append(dataset)\n",
    "\n",
    "\n",
    "# concatenate all datasets\n",
    "combined_dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "print(f\"combined_dataset has {len(combined_dataset)} trajectories\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max rtg:  94.55021\n",
      "min rtg:  -6.359052\n"
     ]
    }
   ],
   "source": [
    "# loop through the dataset and find the highest and lowest reward\n",
    "max_rtg = -math.inf\n",
    "min_rtg = math.inf\n",
    "for dataset in datasets:\n",
    "    for rtg in dataset.rtg:\n",
    "        max_rtg = max(max_rtg, rtg.max())\n",
    "        min_rtg = min(min_rtg, rtg.min())\n",
    "\n",
    "\n",
    "print(\"max rtg: \", max_rtg)\n",
    "print(\"min rtg: \", min_rtg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "batch_size = 16\n",
    "# small learning rate to try to avoid mixed precision caused NaNs\n",
    "lr = 3e-5\n",
    "wt_decay = 1e-4\n",
    "warmup_steps = 10000\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from the concatenated dataset\n",
    "dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state type:  torch.float32\n",
      "actions type:  torch.float32\n",
      "rtg type:  torch.float32\n",
      "timestep type:  torch.int64\n",
      "traj_mask type:  torch.int64\n"
     ]
    }
   ],
   "source": [
    "# define model parameters\n",
    "# sample 1 batch from dataloader\n",
    "state, actions, rtg, timestep, traj_mask = next(iter(dataloader))\n",
    "# use batch shape to determine state dimension\n",
    "state_dim = state.shape[-1]\n",
    "act_dim = actions.shape[-1] # discrete action space\n",
    "# use batch shape to determine context length\n",
    "\n",
    "# check return tensor type\n",
    "print('state type: ', state.dtype)\n",
    "print('actions type: ', actions.dtype)\n",
    "print('rtg type: ', rtg.dtype)\n",
    "print('timestep type: ', timestep.dtype)\n",
    "print('traj_mask type: ', traj_mask.dtype)\n",
    "\n",
    "\n",
    "n_blocks = 4 # number of transformer blocks\n",
    "h_dim = 96 # hidden dimension\n",
    "n_heads = 8 # number of heads in multi-head attention\n",
    "drop_p = 0.1 # dropout probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = DecisionTransformer(state_dim, act_dim, n_blocks, h_dim, context_len, n_heads, drop_p).to(device)\n",
    "# set model to be the same dtype as input\n",
    "model.float()\n",
    "# create optimizer\n",
    "# use larger eps to try to avoid mixed precision overflow caused NaNs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wt_decay, eps=1e-6)\n",
    "\n",
    "# create scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, (step + 1) / warmup_steps))\n",
    "\n",
    "# create a GradScaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler(growth_interval=150)\n",
    "min_scale = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 844144\n"
     ]
    }
   ],
   "source": [
    "# get the model parameters size\n",
    "n_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(f\"Number of parameters: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state type:  torch.float32\n",
      "actions type:  torch.float32\n",
      "rtg type:  torch.float32\n",
      "timestep type:  torch.int64\n",
      "traj_mask type:  torch.int64\n",
      "shape state: torch.Size([32, 30, 13])\n",
      "shape rtg: torch.Size([32, 30, 1])\n",
      "shape timestep: torch.Size([32, 30])\n",
      "shape actions: torch.Size([32, 30, 2])\n",
      "shape act_preds: torch.Size([32, 30, 2])\n",
      "shape action_targets: torch.Size([32, 30, 2])\n",
      "torch.Size([894, 2])\n",
      "torch.Size([894, 2])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test run the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    state, actions, rtg, timestep , traj_mask= next(iter(dataloader))\n",
    "    state = state.to(device)\n",
    "    actions = actions.to(device).float()\n",
    "    rtg = rtg.to(device)\n",
    "    timestep = timestep.to(device)\n",
    "    traj_mask = traj_mask.to(device)\n",
    "    action_targets = torch.clone(actions).detach().to(device)\n",
    "    # check return tensor type\n",
    "    print('state type: ', state.dtype)\n",
    "    print('actions type: ', actions.dtype)\n",
    "    print('rtg type: ', rtg.dtype)\n",
    "    print('timestep type: ', timestep.dtype)\n",
    "    print('traj_mask type: ', traj_mask.dtype)\n",
    "    # check shape of state\n",
    "    print(f\"shape state: {state.shape}\")\n",
    "    # check shape of rtg\n",
    "    print(f\"shape rtg: {rtg.shape}\")\n",
    "    # check shape of timestep\n",
    "    print(f\"shape timestep: {timestep.shape}\")\n",
    "    # check shape of actions\n",
    "    print(f\"shape actions: {actions.shape}\")\n",
    "\n",
    "    return_preds, state_preds, act_preds = model.forward(state, rtg, timestep, actions)\n",
    "\n",
    "    print(f\"shape act_preds: {act_preds.shape}\")\n",
    "    print(f\"shape action_targets: {action_targets.shape}\")\n",
    "    \n",
    "    # consider only the action that are padded\n",
    "    act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "    action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "    # check shape of action targets\n",
    "    print(action_targets.shape)\n",
    "    # check shape of action predictions\n",
    "    print(act_preds.shape)\n",
    "\n",
    "# check for nan values and inf values in the input and the output of the model\n",
    "print(torch.isnan(state).any())\n",
    "print(torch.isnan(rtg).any())\n",
    "print(torch.isnan(timestep).any())\n",
    "print(torch.isnan(actions).any())\n",
    "print(torch.isnan(act_preds).any())\n",
    "print(torch.isnan(action_targets).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# get the start time to calculate training time\n",
    "import datetime\n",
    "\n",
    "# custom training function which take in the model, dataset, optimizer, scheduler, scaler, n_epochs, min_scale\n",
    "def train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale):\n",
    "\n",
    "    # record the start time\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # define training parameters\n",
    "    log_action_losses = []\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for state, actions, rtg, timestep, traj_mask in tqdm(dataloader):\n",
    "            # get batch data to device\n",
    "            state = state.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rtg = rtg.to(device).float()\n",
    "            timestep = timestep.to(device)\n",
    "            traj_mask = traj_mask.to(device)\n",
    "\n",
    "            action_targets = torch.clone(actions).detach().to(device)\n",
    "\n",
    "            # Zeroes out the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run forward pass with autocasting\n",
    "            # disable autocasting for now to avoid mixed precision caused NaNs\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                _, _, act_preds = model.forward(state, rtg, timestep, actions)\n",
    "\n",
    "                # consider only the action that are not padded\n",
    "                act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "                action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "                # calculate losses just for actions\n",
    "                loss = F.mse_loss(act_preds, action_targets, reduction='mean')\n",
    "\n",
    "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # unscale the gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            # Clips the gradients by norm\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Updates the learning rate according to the scheduler\n",
    "            scheduler.step()\n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            # enforce min scale to avoid mixed precision caused NaNs\n",
    "            if scaler.get_scale() < min_scale:\n",
    "                scaler._scale = torch.tensor(min_scale).to(scaler._scale)\n",
    "        \n",
    "            # append action loss to log\n",
    "            log_action_losses.append(loss.detach().cpu().item())\n",
    "\n",
    "        # print every 10 loss log\n",
    "        if epoch % 100 == 0 or epoch == n_epochs - 1:\n",
    "            print(f'Epoch {epoch}: Loss: {log_action_losses[-1]}')\n",
    "\n",
    "    # record the end time\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f'Training time: {end_time - start_time}')\n",
    "    \n",
    "    return model, log_action_losses\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 51/182 [00:11<00:29,  4.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train model on each dataloader and store log_action_losses in a list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m _, log_action_losses \u001b[39m=\u001b[39m train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale)\n",
      "Cell \u001b[0;32mIn[90], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m     17\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mfor\u001b[39;00m state, actions, rtg, timestep, traj_mask \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     20\u001b[0m         \u001b[39m# get batch data to device\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m         actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1162\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1163\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1164\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1165\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1012\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model on each dataloader and store log_action_losses in a list\n",
    "_, log_action_losses = train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot log curve    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save model using torch.save() and save it to a directory\n",
    "directory = 'model'\n",
    "model_name = 'AAPL_model.pt'\n",
    "if not os.path.exists(directory):\n",
    "     os.makedirs(directory)\n",
    "torch.save(model.state_dict(), os.path.join(directory, model_name))\n",
    "\n",
    "# write model parameters to a json file\n",
    "\n",
    "model_params = {\n",
    "     'state_dim': state_dim,\n",
    "     'act_dim': act_dim,\n",
    "     'n_blocks': n_blocks,\n",
    "     'h_dim': h_dim,\n",
    "     'context_len': context_len,\n",
    "     'n_heads': n_heads,\n",
    "     'drop_p': drop_p,\n",
    "}\n",
    "with open(os.path.join(directory, 'AAPL_model_params.json'), 'w') as f:\n",
    "     json.dump(model_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
