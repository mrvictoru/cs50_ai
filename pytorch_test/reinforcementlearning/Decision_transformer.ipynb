{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# this notebook will use a basic GPT based decision transformer in offline reinforcement learning setting to create bot for trading stock\n",
    "# get cuda device\n",
    "# import libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cust_transf import DecisionTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# utility function to compute the discounted cumulative sum of a vector\n",
    "def discount_cumsum(x, gamma):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    \n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    \n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        \n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "    return disc_cumsum\n",
    "\n",
    "# utility function to evaluate the performance of the agent on a given environment\n",
    "# TODO: change it to work with custom environment\n",
    "def evaluate(model, device, context_len, env, rtg_target, rtg_scale, \n",
    "            num_eval_ep=10, max_test_ep_len=28, state_mean=None, state_std=None, render=False):\n",
    "    eval_batch_size = 1\n",
    "\n",
    "    results = {}\n",
    "    total_reward = 0\n",
    "    total_length = 0\n",
    "\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "\n",
    "    state_mean = torch.zeros((state_dim,)).to(device) if state_mean is None else torch.from_numpy(state_mean).to(device)\n",
    "    state_std = torch.ones((state_dim,)).to(device) if state_std is None else torch.from_numpy(state_std).to(device)\n",
    "    \n",
    "    # create timestep for transformer\n",
    "    timesteps = torch.arange(start=0, end=max_test_ep_len, step=1)\n",
    "    timesteps = timesteps.unsqueeze(0).repeat(eval_batch_size, 1).to(device)\n",
    "\n",
    "    # evaluate the agent\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _ in range(num_eval_ep):\n",
    "\n",
    "            # zeros place holders\n",
    "            actions = torch.zeros((eval_batch_size, max_test_ep_len, act_dim),\n",
    "                                dtype=torch.float32, device=device)\n",
    "\n",
    "            states = torch.zeros((eval_batch_size, max_test_ep_len, state_dim),\n",
    "                                dtype=torch.float32, device=device)\n",
    "            \n",
    "            rewards_to_go = torch.zeros((eval_batch_size, max_test_ep_len, 1),\n",
    "                                dtype=torch.float32, device=device)\n",
    "            \n",
    "            # init episode\n",
    "            running_state = env.reset()\n",
    "            running_reward = 0\n",
    "            running_rtg = rtg_target / rtg_scale\n",
    "\n",
    "            for t in range(max_test_ep_len):\n",
    "\n",
    "                total_timesteps += 1\n",
    "\n",
    "                # add state in placeholder and normalize\n",
    "                states[0, t] = torch.from_numpy(running_state).to(device)\n",
    "                states[0, t] = (states[0, t] - state_mean) / state_std\n",
    "\n",
    "                # calcualate running rtg and add in placeholder\n",
    "                running_rtg = running_rtg - (running_reward / rtg_scale)\n",
    "                rewards_to_go[0, t] = running_rtg\n",
    "\n",
    "                if t < context_len:\n",
    "                    _, act_preds, _ = model.forward(timesteps[:,:context_len],\n",
    "                                                states[:,:context_len],\n",
    "                                                actions[:,:context_len],\n",
    "                                                rewards_to_go[:,:context_len])\n",
    "                    act = act_preds[0, t].detach()\n",
    "                else:\n",
    "                    _, act_preds, _ = model.forward(timesteps[:,t-context_len+1:t+1],\n",
    "                                                states[:,t-context_len+1:t+1],\n",
    "                                                actions[:,t-context_len+1:t+1],\n",
    "                                                rewards_to_go[:,t-context_len+1:t+1])\n",
    "                    act = act_preds[0, -1].detach()\n",
    "\n",
    "\n",
    "                running_state, running_reward, done, _ = env.step(act.cpu().numpy())\n",
    "\n",
    "                # add action in placeholder\n",
    "                actions[0, t] = act\n",
    "\n",
    "                total_reward += running_reward\n",
    "\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "    results['eval/avg_reward'] = total_reward / num_eval_ep\n",
    "    results['eval/avg_ep_len'] = total_timesteps / num_eval_ep\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3a69897addd28b22\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-3a69897addd28b22/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1184.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# test load dataset\n",
    "from datasets import load_dataset\n",
    "filename = 'AAPL_2190_2016-01-01_1d_random_replaybuffer.json'\n",
    "data = load_dataset(\"json\", data_files = filename, field = 'data').with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1509, 13])\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['state'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# define a custom dataset class which loads the data, modifies the reward to be the discounted cumulative sum and apply trajectory masking\n",
    "class CustomTrajDataset(Dataset):\n",
    "    def __init__(self, file_name, context_len, gamma):\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # load the data\n",
    "        data = load_dataset(\"json\", data_files = file_name, field = 'data').with_format('torch')\n",
    "        self.data = data['train']\n",
    "\n",
    "        # calculate min len, the mean and std of the state and rtg for all data\n",
    "        stateshape = data['train']['state'].shape\n",
    "        self.state_mean = torch.mean(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        self.state_std = torch.std(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        # calculate the discounted cumulative sum\n",
    "        discount_reward = discount_cumsum(data['reward'], self.gamma)\n",
    "        #\n",
    "        # get the state, action, reward and next state\n",
    "        return (data['state']-self.state_mean)/self.state_std, data['action'], torch.from_numpy(discount_reward), data['timestep']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3a69897addd28b22\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-3a69897addd28b22/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1038.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# load huggingface dataset from json file\n",
    "filename = 'AAPL_2190_2016-01-01_1d_random_replaybuffer.json'\n",
    "\n",
    "dataset = CustomTrajDataset(filename, gamma = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "batch_size = 2\n",
    "# small learning rate to try to avoid mixed precision caused NaNs\n",
    "lr = 3e-5\n",
    "wt_decay = 1e-4\n",
    "warmup_steps = 10000\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from dataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "# sample 1 batch from dataloader\n",
    "norm_state, actions, rtg, timestep = next(iter(dataloader))\n",
    "# use batch shape to determine state dimension\n",
    "state_dim = norm_state.shape[-1]\n",
    "act_dim = actions.shape[-1] # discrete action space\n",
    "# use batch shape to determine context length\n",
    "context_len = timestep.shape[-1] # K in decision transformer\n",
    "\n",
    "n_blocks = 4 # number of transformer blocks\n",
    "h_dim = 96 # hidden dimension\n",
    "n_heads = 6 # number of heads in multi-head attention\n",
    "drop_p = 0.1 # dropout probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = DecisionTransformer(state_dim, act_dim, n_blocks, h_dim, context_len, n_heads, drop_p).to(device)\n",
    "\n",
    "# create optimizer\n",
    "# use larger eps to try to avoid mixed precision overflow caused NaNs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wt_decay, eps=1e-6)\n",
    "\n",
    "# create scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, (step + 1) / warmup_steps))\n",
    "\n",
    "# create a GradScaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler(growth_interval=150)\n",
    "min_scale = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1509, 13])\n",
      "torch.Size([4, 1509, 1])\n",
      "torch.Size([4, 1509])\n",
      "torch.Size([4, 1509, 2])\n",
      "torch.Size([4, 1509, 2])\n",
      "torch.Size([4, 1509, 2])\n",
      "torch.Size([6036, 2])\n",
      "torch.Size([6036, 2])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test run the model\n",
    "with torch.no_grad():\n",
    "    norm_state, actions, rtg, timestep = next(iter(dataloader))\n",
    "    norm_state = norm_state.to(device)\n",
    "    actions = actions.to(device)\n",
    "    rtg = rtg.to(device)\n",
    "    timestep = timestep.to(device)\n",
    "    action_targets = torch.clone(actions).detach().to(device)\n",
    "    return_preds, state_preds, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "    # check shape of norm_state\n",
    "    print(norm_state.shape)\n",
    "    # check shape of rtg\n",
    "    print(rtg.shape)\n",
    "    # check shape of timestep\n",
    "    print(timestep.shape)\n",
    "    # check shape of actions\n",
    "    print(actions.shape)\n",
    "    print(act_preds.shape)\n",
    "    print(action_targets.shape)\n",
    "    \n",
    "    # calculate losses just for actions\n",
    "    act_preds = act_preds.view(-1, act_dim)\n",
    "    action_targets = action_targets.view(-1, act_dim)\n",
    "\n",
    "    # check shape of action targets\n",
    "    print(action_targets.shape)\n",
    "    # check shape of action predictions\n",
    "    print(act_preds.shape)\n",
    "\n",
    "# check for nan values and inf values in the input and the output of the model\n",
    "print(torch.isnan(norm_state).any())\n",
    "print(torch.isnan(rtg).any())\n",
    "print(torch.isnan(timestep).any())\n",
    "print(torch.isnan(actions).any())\n",
    "print(torch.isnan(act_preds).any())\n",
    "print(torch.isnan(action_targets).any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1709,  0.2726],\n",
      "        [-0.3959,  0.1280],\n",
      "        [-0.4118, -0.5362],\n",
      "        ...,\n",
      "        [ 0.4393,  0.5826],\n",
      "        [ 0.5670, -0.2079],\n",
      "        [-0.0441,  0.1552]], device='cuda:0')\n",
      "tensor([[ 0.0221,  0.4075],\n",
      "        [-0.9087,  0.1251],\n",
      "        [-0.4329,  0.0531],\n",
      "        ...,\n",
      "        [ 0.0811,  0.2015],\n",
      "        [ 0.5435,  0.6152],\n",
      "        [-0.1350,  0.5347]], device='cuda:0')\n",
      "tensor([[[-0.9650, -0.9705, -0.9736,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9918, -0.9805, -0.9910,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9727, -0.9776, -0.9885,  ..., -1.5698, -1.8747, -1.4156],\n",
      "         ...,\n",
      "         [ 2.6713,  2.6457,  2.7065,  ...,  2.5513,  1.3809,  1.9503],\n",
      "         [ 2.7016,  2.7317,  2.7509,  ...,  2.5545,  1.3809,  1.9503],\n",
      "         [ 2.7765,  2.7536,  2.7870,  ...,  2.5952,  1.3809,  1.9503]],\n",
      "\n",
      "        [[-0.9650, -0.9705, -0.9736,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9918, -0.9805, -0.9910,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9727, -0.9776, -0.9885,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         ...,\n",
      "         [ 2.6713,  2.6457,  2.7065,  ...,  2.6464,  0.6858,  1.0026],\n",
      "         [ 2.7016,  2.7317,  2.7509,  ...,  2.6464,  0.6858,  1.0026],\n",
      "         [ 2.7765,  2.7536,  2.7870,  ...,  2.6464,  0.6858,  1.0026]],\n",
      "\n",
      "        [[-0.9650, -0.9705, -0.9736,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9918, -0.9805, -0.9910,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9727, -0.9776, -0.9885,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         ...,\n",
      "         [ 2.6713,  2.6457,  2.7065,  ...,  2.5555,  1.3676,  2.0419],\n",
      "         [ 2.7016,  2.7317,  2.7509,  ...,  2.6180,  1.3676,  2.0419],\n",
      "         [ 2.7765,  2.7536,  2.7870,  ...,  2.6180,  1.3676,  2.0419]],\n",
      "\n",
      "        [[-0.9650, -0.9705, -0.9736,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9918, -0.9805, -0.9910,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         [-0.9727, -0.9776, -0.9885,  ..., -1.5698, -1.8749, -1.4157],\n",
      "         ...,\n",
      "         [ 2.6713,  2.6457,  2.7065,  ...,  2.4495,  1.8940,  2.5415],\n",
      "         [ 2.7016,  2.7317,  2.7509,  ...,  2.4495,  1.8940,  2.5415],\n",
      "         [ 2.7765,  2.7536,  2.7870,  ...,  2.4495,  1.8940,  2.5415]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(act_preds)\n",
    "print(action_targets)\n",
    "print(norm_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:01<14:23,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/500 [00:08<17:03,  2.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m log_action_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m norm_state, actions, rtg, timestep \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# get batch data to device\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     norm_state \u001b[39m=\u001b[39m norm_state\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb Cell 11\u001b[0m in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# calculate the discounted cumulative sum\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     discount_reward \u001b[39m=\u001b[39m discount_cumsum(data[\u001b[39m'\u001b[39m\u001b[39mreward\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/arrow_dataset.py:2343\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m     \u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\n\u001b[1;32m   2344\u001b[0m         key,\n\u001b[1;32m   2345\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/arrow_dataset.py:2328\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, decoded\u001b[39m=\u001b[39mdecoded, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2327\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 2328\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2329\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[1;32m   2330\u001b[0m )\n\u001b[1;32m   2331\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/formatting.py:509\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    507\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[1;32m    510\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    511\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/formatting.py:282\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable, query_type: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 282\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_row(pa_table)\n\u001b[1;32m    283\u001b[0m     \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    284\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:83\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoded:\n\u001b[1;32m     82\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_features_decoder\u001b[39m.\u001b[39mdecode_row(row)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecursive_tensorize(row)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:77\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_tensorize\u001b[39m(\u001b[39mself\u001b[39m, data_struct: \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m map_nested(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recursive_tensorize, data_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/utils/py_utils.py:429\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    427\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[0;32m--> 429\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m    430\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    431\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    432\u001b[0m     ]\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     num_proc \u001b[39m=\u001b[39m num_proc \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/utils/py_utils.py:430\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[1;32m    429\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 430\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    431\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    432\u001b[0m     ]\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     num_proc \u001b[39m=\u001b[39m num_proc \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/utils/py_utils.py:331\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 331\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    333\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:73\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m data_struct\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:  \u001b[39m# torch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecursive_tensorize(substruct) \u001b[39mfor\u001b[39;00m substruct \u001b[39min\u001b[39;00m data_struct])\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensorize(data_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:73\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m data_struct\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:  \u001b[39m# torch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecursive_tensorize(substruct) \u001b[39mfor\u001b[39;00m substruct \u001b[39min\u001b[39;00m data_struct])\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensorize(data_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:77\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_tensorize\u001b[39m(\u001b[39mself\u001b[39m, data_struct: \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m map_nested(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recursive_tensorize, data_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/utils/py_utils.py:421\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39m# Singleton\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 421\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    423\u001b[0m disable_tqdm \u001b[39m=\u001b[39m disable_tqdm \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m    424\u001b[0m iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_struct\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m data_struct\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:74\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m data_struct\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:  \u001b[39m# torch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     73\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecursive_tensorize(substruct) \u001b[39mfor\u001b[39;00m substruct \u001b[39min\u001b[39;00m data_struct])\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensorize(data_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:53\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m, \u001b[39mtype\u001b[39m(\u001b[39mNone\u001b[39;00m))):\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m---> 53\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(value, (np\u001b[39m.\u001b[39;49mcharacter, np\u001b[39m.\u001b[39;49mndarray)) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(value\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mcharacter):\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     56\u001b[0m default_dtype \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create training loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get the start time to calculate training time\n",
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "#training_log = {'epoch':[], 'loss':[], 'eval/avg_reward':[], 'eval/avg_ep_len':[]} # training log\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    model.train()\n",
    "    log_action_losses = []\n",
    "\n",
    "    for norm_state, actions, rtg, timestep in tqdm(dataloader):\n",
    "        # get batch data to device\n",
    "        norm_state = norm_state.to(device)\n",
    "        actions = actions.to(device)\n",
    "        rtg = rtg.to(device)\n",
    "        timestep = timestep.to(device)\n",
    "\n",
    "        action_targets = torch.clone(actions).detach().to(device)\n",
    "\n",
    "        # Zeroes out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run forward pass with autocasting\n",
    "        # disable autocasting for now to avoid mixed precision caused NaNs\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            return_preds, state_preds, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "            # calculate losses just for actions\n",
    "            act_preds = act_preds.view(-1, act_dim)\n",
    "            action_targets = action_targets.view(-1, act_dim)\n",
    "\n",
    "            loss = F.mse_loss(act_preds, action_targets, reduction='mean')\n",
    "\n",
    "        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # unscale the gradients\n",
    "        scaler.unscale_(optimizer)\n",
    "        # Clips the gradients by norm\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        # Updates the learning rate according to the scheduler\n",
    "        scheduler.step()\n",
    "        # Updates the scale for next iteration.\n",
    "        scaler.update()\n",
    "        # enforce min scale to avoid mixed precision caused NaNs\n",
    "        if scaler.get_scale() < min_scale:\n",
    "            #print('current scale is ', scaler.get_scale())\n",
    "            scaler._scale = torch.tensor(min_scale).to(scaler._scale)\n",
    "            #print('new scale is ', scaler.get_scale())\n",
    "        \n",
    "        # append action loss to log\n",
    "        log_action_losses.append(loss.detach().cpu().item())\n",
    "        # print every 100 loss log\n",
    "        if len(log_action_losses) % 10 == 0 or len(log_action_losses) == 1:\n",
    "            print('Loss: ', log_action_losses[-1])\n",
    "    \n",
    "\n",
    "# record training time\n",
    "end_time = datetime.datetime.now()\n",
    "print('Training time: ', end_time - start_time)\n",
    "\n",
    "# create environment to evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test act_embedding\n",
    "embed_act = nn.Embedding(act_dim+1, h_dim)\n",
    "embed_timestep = nn.Embedding(4096, h_dim)\n",
    "embed_rtg = nn.Linear(1, h_dim)\n",
    "embed_state = nn.Linear(state_dim, h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "actions = batch['action']\n",
    "timesteps = batch['timestep']\n",
    "reward = batch['reward']\n",
    "states = batch['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 1])\n",
      "torch.Size([4, 28, 1])\n",
      "torch.Size([4, 28])\n",
      "torch.Size([4, 28, 5])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([4096, 128])\n",
      "torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "print(actions.shape)\n",
    "print(reward.shape)\n",
    "print(timesteps.shape)\n",
    "print(states.shape)\n",
    "print(embed_act.weight.shape)\n",
    "print(embed_rtg.weight.shape)\n",
    "print(embed_timestep.weight.shape)\n",
    "print(embed_state.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 128])\n"
     ]
    }
   ],
   "source": [
    "time_emb = embed_timestep(timesteps)\n",
    "print(time_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "statesize = embed_state(states).shape\n",
    "timesize = embed_timestep(timesteps).shape\n",
    "\n",
    "# compare the size of the embedding\n",
    "print(statesize == timesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_emb = embed_state(states) + time_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_emb = embed_rtg(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_emb = torch.squeeze(embed_act(actions))\n",
    "act_emb = act_emb + time_emb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
