{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# this notebook will use a basic GPT based decision transformer in offline reinforcement learning setting to create bot for trading stock\n",
    "# get cuda device\n",
    "# import libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cust_transf import DecisionTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.load import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# utility function to compute the discounted cumulative sum of a vector\n",
    "def discount_cumsum(x, gamma):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "    return disc_cumsum\n",
    "\n",
    "# define a custom dataset class which loads the data, modifies the reward to be the discounted cumulative sum and apply trajectory masking\n",
    "class CustomTrajDataset(Dataset):\n",
    "    def __init__(self, file_name, context_len, gamma, rtg_scale):\n",
    "        self.gamma = gamma\n",
    "        self.context_len = context_len\n",
    "\n",
    "        # load the data\n",
    "        data = load_dataset(\"json\", data_files = file_name, field = 'data')\n",
    "        self.data_state = np.array(data['train']['state'], dtype=np.float32)\n",
    "        self.data_action = np.array(data['train']['action'], dtype=np.float32)\n",
    "        self.rtg = np.array(data['train']['reward'], dtype=np.float32)\n",
    "\n",
    "\n",
    "        # calculate min len, the mean and std of the state and rtg for all data\n",
    "        self.stateshape = self.data_state.shape\n",
    "        # calculate mean of state and rtg with numpy\n",
    "        self.state_mean = np.mean(self.data_state, axis=(-2,-1), keepdims=True)\n",
    "        self.state_std = np.std(np.abs(self.data_state), axis=(-2,-1), keepdims=True)\n",
    "        #self.state_mean = torch.mean(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        #self.state_std = torch.std(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        self.norm_state = (self.data_state - self.state_mean) / self.state_std\n",
    "\n",
    "        self.rtg = np.apply_along_axis(discount_cumsum, 1, data['train']['reward'], self.gamma) # type: ignore\n",
    "        self.rtg = self.rtg / rtg_scale\n",
    "\n",
    "    def get_state_stats(self):\n",
    "        return self.state_mean, self.state_std        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.stateshape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        state = self.norm_state[idx]\n",
    "        action = self.data_action[idx]\n",
    "        rtg = self.rtg[idx]\n",
    "\n",
    "        data_len = state.shape[0]\n",
    "        \n",
    "        if data_len > self.context_len:\n",
    "            # sample random start index\n",
    "            start_idx = np.random.randint(0, data_len - self.context_len)\n",
    "            # slice the data and convert to torch\n",
    "            state = torch.from_numpy(state[start_idx:start_idx+self.context_len])\n",
    "            action = torch.from_numpy(action[start_idx:start_idx+self.context_len])\n",
    "            rtg = torch.from_numpy(rtg[start_idx:start_idx+self.context_len])\n",
    "            timesteps = torch.arange(start=start_idx, end=start_idx + self.context_len, step=1)\n",
    "            # trajectory mask\n",
    "            mask = torch.ones(self.context_len, dtype=torch.long)\n",
    "        else:\n",
    "            padding_len = self.context_len - data_len\n",
    "\n",
    "            # pad the data with zeros\n",
    "            state = torch.from_numpy(state)\n",
    "            state = torch.cat([state, torch.zeros((padding_len, *state.shape[1:]))], dim=0)\n",
    "\n",
    "            action = torch.from_numpy(action)\n",
    "            action = torch.cat([action, torch.zeros((padding_len, *action.shape[1:]))], dim=0)\n",
    "\n",
    "            rtg = torch.from_numpy(rtg)\n",
    "            rtg = torch.cat([rtg, torch.zeros((padding_len, *rtg.shape[1:]))], dim=0)\n",
    "\n",
    "            timesteps = torch.arange(start=0, end=self.context_len, step=1)\n",
    "\n",
    "            # trajectory mask\n",
    "            mask = torch.cat([torch.ones(data_len, dtype=torch.long), torch.zeros(padding_len, dtype=torch.long)], dim=0)\n",
    "        \n",
    "        return state, action, rtg, timesteps, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-9b529c6ea512e6e3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.75it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-0bf8fa05208b6986/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 223.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-3f4820e3e23aa5e3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4253.86it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 51.01it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-3f4820e3e23aa5e3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1036.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-5eb96d451a6d6f10/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 50.17it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-5eb96d451a6d6f10/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1074.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-4d259c4d25298c05/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4219.62it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 128.04it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-4d259c4d25298c05/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1070.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-777faf1abc5243b4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 43.53it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-777faf1abc5243b4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1079.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-9046201c9bb75691/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4782.56it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 52.31it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-9046201c9bb75691/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1020.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-01130f1bcc3f6c1d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 12409.18it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1080.45it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-01130f1bcc3f6c1d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1056.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-73cf32995c39088a/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5102.56it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 31.07it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-73cf32995c39088a/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1062.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-58e8dd303af5c481/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 85.20it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-58e8dd303af5c481/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 914.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-5db6b286d56f7818/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1083.80it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-5db6b286d56f7818/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 972.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-48256180deb3fa0c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 92.30it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-48256180deb3fa0c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1047.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-cb7b69133e4279f9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 8355.19it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 136.31it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-cb7b69133e4279f9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1084.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/victoru/.cache/huggingface/datasets/json/default-d7855d2ea3173df3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2551.28it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 68.08it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/victoru/.cache/huggingface/datasets/json/default-d7855d2ea3173df3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1017.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "# create datasets and store in list from the list of filenames \n",
    "context_len = 30\n",
    "Max_balance = 2147483647\n",
    "gamma = 0.99\n",
    "\n",
    "datasets = []\n",
    "for name in full_filenames:\n",
    "    dataset = CustomTrajDataset(name, context_len, gamma, Max_balance)\n",
    "    datasets.append(dataset)\n",
    "\n",
    "# concatenate all datasets\n",
    "combined_dataset = torch.utils.data.ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max reward:  0.002264376001618792\n",
      "min reward:  -9.086438618410393e-06\n"
     ]
    }
   ],
   "source": [
    "# loop through the dataset and find the highest and lowest reward\n",
    "max_reward = -math.inf\n",
    "min_reward = math.inf\n",
    "for dataset in datasets:\n",
    "    max_reward = max(max_reward, dataset.rtg.max())\n",
    "    min_reward = min(min_reward, dataset.rtg.min())\n",
    "\n",
    "print(\"max reward: \", max_reward)\n",
    "print(\"min reward: \", min_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "batch_size = 32\n",
    "# small learning rate to try to avoid mixed precision caused NaNs\n",
    "lr = 3e-5\n",
    "wt_decay = 1e-4\n",
    "warmup_steps = 10000\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from the concatenated dataset\n",
    "dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "# sample 1 batch from dataloader\n",
    "norm_state, actions, rtg, timestep, traj_mask = next(iter(dataloader))\n",
    "# use batch shape to determine state dimension\n",
    "state_dim = norm_state.shape[-1]\n",
    "act_dim = actions.shape[-1] # discrete action space\n",
    "# use batch shape to determine context length\n",
    "\n",
    "\n",
    "n_blocks = 4 # number of transformer blocks\n",
    "h_dim = 96 # hidden dimension\n",
    "n_heads = 8 # number of heads in multi-head attention\n",
    "drop_p = 0.1 # dropout probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = DecisionTransformer(state_dim, act_dim, n_blocks, h_dim, context_len, n_heads, drop_p).to(device)\n",
    "\n",
    "# create optimizer\n",
    "# use larger eps to try to avoid mixed precision overflow caused NaNs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wt_decay, eps=1e-6)\n",
    "\n",
    "# create scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, (step + 1) / warmup_steps))\n",
    "\n",
    "# create a GradScaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler(growth_interval=150)\n",
    "min_scale = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 844144\n"
     ]
    }
   ],
   "source": [
    "# get the model parameters size\n",
    "n_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(f\"Number of parameters: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape norm_state: torch.Size([32, 20, 13])\n",
      "shape rtg: torch.Size([32, 20, 1])\n",
      "shape timestep: torch.Size([32, 20])\n",
      "shape actions: torch.Size([32, 20, 2])\n",
      "shape act_preds: torch.Size([32, 20, 2])\n",
      "shape action_targets: torch.Size([32, 20, 2])\n",
      "torch.Size([640, 2])\n",
      "torch.Size([640, 2])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test run the model\n",
    "with torch.no_grad():\n",
    "    norm_state, actions, rtg, timestep , traj_mask= next(iter(dataloader))\n",
    "    norm_state = norm_state.to(device)\n",
    "    actions = actions.to(device)\n",
    "    # convert rtg to float\n",
    "    rtg = rtg.to(device).float()\n",
    "    timestep = timestep.to(device)\n",
    "    traj_mask = traj_mask.to(device)\n",
    "    action_targets = torch.clone(actions).detach().to(device)\n",
    "    return_preds, state_preds, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "    # check shape of norm_state\n",
    "    print(f\"shape norm_state: {norm_state.shape}\")\n",
    "    # check shape of rtg\n",
    "    print(f\"shape rtg: {rtg.shape}\")\n",
    "    # check shape of timestep\n",
    "    print(f\"shape timestep: {timestep.shape}\")\n",
    "    # check shape of actions\n",
    "    print(f\"shape actions: {actions.shape}\")\n",
    "    print(f\"shape act_preds: {act_preds.shape}\")\n",
    "    print(f\"shape action_targets: {action_targets.shape}\")\n",
    "    \n",
    "    # consider only the action that are padded\n",
    "    act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "    action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "    # check shape of action targets\n",
    "    print(action_targets.shape)\n",
    "    # check shape of action predictions\n",
    "    print(act_preds.shape)\n",
    "\n",
    "# check for nan values and inf values in the input and the output of the model\n",
    "print(torch.isnan(norm_state).any())\n",
    "print(torch.isnan(rtg).any())\n",
    "print(torch.isnan(timestep).any())\n",
    "print(torch.isnan(actions).any())\n",
    "print(torch.isnan(act_preds).any())\n",
    "print(torch.isnan(action_targets).any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# get the start time to calculate training time\n",
    "import datetime\n",
    "\n",
    "# custom training function which take in the model, dataset, optimizer, scheduler, scaler, n_epochs, min_scale\n",
    "def train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale):\n",
    "\n",
    "    # record the start time\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # define training parameters\n",
    "    log_action_losses = []\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "\n",
    "        for norm_state, actions, rtg, timestep, traj_mask in tqdm(dataloader):\n",
    "            # get batch data to device\n",
    "            norm_state = norm_state.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rtg = rtg.to(device).float()\n",
    "            timestep = timestep.to(device)\n",
    "            traj_mask = traj_mask.to(device)\n",
    "\n",
    "            action_targets = torch.clone(actions).detach().to(device)\n",
    "\n",
    "            # Zeroes out the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run forward pass with autocasting\n",
    "            # disable autocasting for now to avoid mixed precision caused NaNs\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                _, _, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "                # consider only the action that are padded\n",
    "                act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "                action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "                # calculate losses just for actions\n",
    "                loss = F.mse_loss(act_preds, action_targets, reduction='mean')\n",
    "\n",
    "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # unscale the gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            # Clips the gradients by norm\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Updates the learning rate according to the scheduler\n",
    "            scheduler.step()\n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            # enforce min scale to avoid mixed precision caused NaNs\n",
    "            if scaler.get_scale() < min_scale:\n",
    "                scaler._scale = torch.tensor(min_scale).to(scaler._scale)\n",
    "        \n",
    "            # append action loss to log\n",
    "            log_action_losses.append(loss.detach().cpu().item())\n",
    "\n",
    "        # print every 10 loss log\n",
    "        if epoch % 100 == 0 or epoch == n_epochs - 1:\n",
    "            print(f'Epoch {epoch}: Loss: {log_action_losses[-1]}')\n",
    "\n",
    "    # record the end time\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f'Training time: {end_time - start_time}')\n",
    "    \n",
    "    return model, log_action_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:02<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.9919530749320984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:01<00:00, 68.32it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.30it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.27it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 66.88it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.68it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.71it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.85it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.79it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.14it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.22it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 71.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.83it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.46it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.32it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.33it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.43it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.37it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.76it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.77it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.65it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.08it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.78it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.09it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.00it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.23it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.08it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 65.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.43it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 63.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.31it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.42it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.03it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.48it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.72it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.94it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 66.80it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 65.60it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.22it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.21it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.59it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 66.72it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.14it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.93it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 62.78it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.27it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.17it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.09it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.17it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.18it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.95it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.36it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.19it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.41it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.68it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.92it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.90it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.27it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.53it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.51it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.30it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.79it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.38it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.74it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.97it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.50it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.66it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.11it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.50it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss: 0.16668927669525146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:01<00:00, 66.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.53it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.66it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.84it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.65it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 71.10it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.07it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.68it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.58it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.76it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.40it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.32it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.77it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.51it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.51it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 67.93it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.21it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.49it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 71.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.29it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.82it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 70.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.27it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.40it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 71.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 68.85it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 71.21it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 69.59it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 74.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.85it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.04it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.67it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.02it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.48it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.44it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.51it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.00it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.36it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.99it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.99it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.83it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.22it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.76it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.74it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.35it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.25it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.88it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.70it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.66it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.08it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.84it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.37it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.77it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.76it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.65it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.05it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.51it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.97it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.59it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.58it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.98it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.44it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.17it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.33it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.46it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.12it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.37it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.23it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.65it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss: 0.23529082536697388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:01<00:00, 83.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.30it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.06it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.43it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.96it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.99it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.80it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.66it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.29it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.93it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.55it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.39it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.07it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.03it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.88it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.12it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.48it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.44it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.32it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.54it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.14it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.34it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.78it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.60it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.61it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.90it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.21it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.36it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.90it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.05it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.70it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.49it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.98it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.98it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.38it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.90it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.68it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.38it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.02it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.38it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.12it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.61it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.74it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.91it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.65it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.46it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.71it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.42it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.46it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.19it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.11it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.70it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.32it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.11it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.34it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.11it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.33it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.39it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.62it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.04it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.50it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.31it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.84it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.90it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.32it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.17it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.03it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.22it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Loss: 0.19295398890972137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:01<00:00, 83.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.12it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.94it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.06it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.59it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.25it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.12it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.96it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.97it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.14it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.39it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.35it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.92it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.85it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.02it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.31it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.40it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.72it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.24it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.58it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.39it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.36it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.96it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.60it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.41it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.82it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.12it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.39it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.62it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.97it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.64it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.62it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.01it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.02it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.20it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.37it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.08it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.34it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.22it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.36it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.16it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.07it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.41it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.78it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.06it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.00it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.06it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.82it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.81it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.37it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.71it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.71it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.80it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.40it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.91it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.17it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.01it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.91it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.24it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.34it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.38it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.06it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.68it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.97it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.31it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.44it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.75it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.05it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.84it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.08it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.80it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.35it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.94it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: Loss: 0.22467394173145294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:01<00:00, 83.02it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.01it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.58it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.84it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.29it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.60it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.70it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.11it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.02it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.40it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.94it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.63it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.25it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.76it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.56it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.33it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 73.13it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 81.44it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.58it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.71it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.17it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 90.05it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 78.92it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.14it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.74it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 80.86it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 75.94it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 73.50it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 77.87it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 77.79it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 77.82it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 78.48it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 78.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.38it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 73.45it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 77.27it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 72.82it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 75.51it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 71.69it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 79.74it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.48it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.36it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.35it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.34it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 84.80it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 81.91it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 81.01it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 81.89it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.77it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 73.91it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 78.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 75.34it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 77.79it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 77.29it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 79.15it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 78.52it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 74.67it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 81.53it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 83.27it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 81.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 79.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 82.61it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.39it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 80.49it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.21it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.28it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 85.85it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.95it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 90.04it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.78it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.73it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.42it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 90.95it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.37it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.47it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.10it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.26it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 90.57it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.35it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.60it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 86.11it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 90.25it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.65it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 90.79it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.82it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 89.31it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 87.76it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.60it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 88.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: Loss: 0.23923668265342712\n",
      "Training time: 0:12:41.472033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train model on each dataloader and store log_action_losses in a list\n",
    "_, log_action_losses = train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model using torch.save() and save it to a directory\n",
    "directory = 'model'\n",
    "model_name = 'AAPL_model.pt'\n",
    "if not os.path.exists(directory):\n",
    "     os.makedirs(directory)\n",
    "torch.save(model.state_dict(), os.path.join(directory, model_name))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
