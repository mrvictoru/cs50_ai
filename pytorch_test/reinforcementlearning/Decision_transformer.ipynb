{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook will use a basic GPT based decision transformer in offline reinforcement learning setting to create bot for trading stock\n",
    "# get cuda device\n",
    "# import libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cust_transf import DecisionTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-fee53e086325bcc9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 902.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets.load import load_dataset\n",
    "\n",
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "data = load_dataset(\"json\", data_files = full_filenames[0], field = 'data')\n",
    "testdata = data['train']\n",
    "data = testdata.with_format('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.82049999e+01, 2.82824993e+01, 2.75524998e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.78474998e+01, 2.78600006e+01, 2.68374996e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.70725002e+01, 2.71625004e+01, 2.63525009e+01, ...,\n",
       "        2.73325005e+01, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.98199997e+01, 3.99375000e+01, 3.90400009e+01, ...,\n",
       "        3.79116863e+01, 2.05510000e+04, 6.07681824e+05],\n",
       "       [3.92625008e+01, 3.93025017e+01, 3.87550011e+01, ...,\n",
       "        3.79116863e+01, 2.05510000e+04, 6.07681824e+05],\n",
       "       [3.90175018e+01, 3.93499985e+01, 3.89225006e+01, ...,\n",
       "        3.79116863e+01, 2.05510000e+04, 6.07681824e+05]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(testdata['state'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (500,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(data[\u001b[39m'\u001b[39;49m\u001b[39mstate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto_list())\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (500,) + inhomogeneous part."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.load import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# utility function to compute the discounted cumulative sum of a vector\n",
    "def discount_cumsum(x, gamma):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "    return disc_cumsum\n",
    "\n",
    "# define a custom dataset class which loads the data, modifies the reward to be the discounted cumulative sum and apply trajectory masking\n",
    "class CustomTrajTrainDataset(Dataset):\n",
    "    def __init__(self, file_name, context_len, gamma, rtg_scale):\n",
    "        self.gamma = gamma\n",
    "        self.context_len = context_len\n",
    "\n",
    "        # load the data\n",
    "        \n",
    "        self.data = load_dataset(\"json\", data_files = file_name, field = 'data')['train']\n",
    "        \"\"\"\n",
    "        self.data_state = np.array(data['train']['state'], dtype=np.float32)\n",
    "        self.data_action = np.array(data['train']['action'], dtype=np.float32)\n",
    "        self.rtg = np.array(data['train']['reward'], dtype=np.float32)\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = self.data.with_format('pandas')\n",
    "        self.rtg = []\n",
    "        #min_len = 10**6\n",
    "        states = []\n",
    "\n",
    "        for traj in self.data['state']:\n",
    "            states.append(np.array(traj, dtype=np.float32))\n",
    "            #if len(traj) < min_len:\n",
    "            #    min_len = len(traj)\n",
    "\n",
    "        for reward in self.data['reward']:\n",
    "            self.rtg.append(discount_cumsum(np.array(reward, dtype=np.float32), 1.0)/rtg_scale)\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: test the following code to see if it works, if so replace the loop above\n",
    "        for reward in self.data['reward'].apply(lambda x: discount_cumsum(np.array(x, dtype=np.float32), 1.0)/rtg_scale):\n",
    "        self.rtg.append(reward)\n",
    "        \"\"\"\n",
    "\n",
    "        states = np.concatenate(states, axis=0)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "        # calculate min len, the mean and std of the state and rtg for all data\n",
    "        self.stateshape = len(self.data['state'])\n",
    "        # calculate mean of state and rtg with numpy\n",
    "\n",
    "        #self.state_mean = torch.mean(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        #self.state_std = torch.std(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        #self.norm_state = (self.data_state - self.state_mean) / self.state_std\n",
    "\n",
    "        #self.rtg = np.apply_along_axis(discount_cumsum, 1, self.data['reward'], self.gamma) # type: ignore\n",
    "        #self.rtg = self.rtg / rtg_scale\n",
    "\n",
    "    def get_state_stats(self):\n",
    "        return self.state_mean, self.state_std        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.stateshape\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # TODO: stack the selected data using np.stack\n",
    "            state = np.array(self.data['state'][idx])\n",
    "            action = np.array(self.data['action'][idx])\n",
    "            rtg = np.array(self.rtg[idx])\n",
    "        except IndexError:\n",
    "            # handle index out of range error\n",
    "            raise IndexError(f\"Index {idx} out of range for dataset with length {len(self.data['state'])}\")\n",
    "\n",
    "\n",
    "        data_len = len(state)\n",
    "        \n",
    "        if data_len > self.context_len:\n",
    "            # sample random start index\n",
    "            start_idx = np.random.randint(0, data_len - self.context_len)\n",
    "            # slice the data and convert to torch\n",
    "            state = torch.from_numpy(state[start_idx:start_idx+self.context_len])\n",
    "            action = torch.from_numpy(action[start_idx:start_idx+self.context_len])\n",
    "            rtg = torch.from_numpy(rtg[start_idx:start_idx+self.context_len])\n",
    "            timesteps = torch.arange(start=start_idx, end=start_idx + self.context_len, step=1)\n",
    "            # trajectory mask\n",
    "            mask = torch.ones(self.context_len, dtype=torch.long)\n",
    "        else:\n",
    "            padding_len = self.context_len - data_len\n",
    "\n",
    "            # pad the data with zeros\n",
    "            state = torch.from_numpy(state)\n",
    "            state = torch.cat([state, torch.zeros((padding_len, *state.shape[1:]))], dim=0)\n",
    "\n",
    "            action = torch.from_numpy(action)\n",
    "            action = torch.cat([action, torch.zeros((padding_len, *action.shape[1:]))], dim=0)\n",
    "\n",
    "            rtg = torch.from_numpy(rtg)\n",
    "            rtg = torch.cat([rtg, torch.zeros((padding_len, *rtg.shape[1:]))], dim=0)\n",
    "\n",
    "            timesteps = torch.arange(start=0, end=self.context_len, step=1)\n",
    "\n",
    "            # trajectory mask\n",
    "            mask = torch.cat([torch.ones(data_len, dtype=torch.long), torch.zeros(padding_len, dtype=torch.long)], dim=0)\n",
    "        \n",
    "        return state, action, rtg, timesteps, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-fee53e086325bcc9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1009.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_2555_2015-01-01_1d_random_replaybuffer.json has 500 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-0d2b6431758d253c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 931.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_14_1_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-c931b78b82e2a521/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 985.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_2_1d_a2c_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-a7fb97aa0b2d2c17/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 854.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_2_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-e3558f3f5b1e1a9f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1063.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_3_1d_a2c_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-5650ad8da88f517f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1048.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_3_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-f0f6506387ff2ddb/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 691.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_167_3_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-a3af101adcd158b1/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1076.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_168_4_1d_a2c_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-1391ec1e9d77eb5a/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1028.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_168_4_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-ad2892aa847ed6ed/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1011.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_168_4_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-111410c52e68511e/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 944.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_25_2_1d_ppo_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-7494b394211bc8ce/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 979.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_326_1_1d_ddpg_replaybuffer.json has 200 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-f82cdf55698959cf/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1066.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaybuffer/AAPL_test_len_504_1_1d_a2c_replaybuffer.json has 200 trajectories\n",
      "combined_dataset has 2900 trajectories\n"
     ]
    }
   ],
   "source": [
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "# create datasets and store in list from the list of filenames \n",
    "context_len = 30\n",
    "Max_balance = 2147483647\n",
    "gamma = 0.99\n",
    "\n",
    "datasets = []\n",
    "for name in full_filenames:\n",
    "    dataset = CustomTrajTrainDataset(name, context_len, gamma, Max_balance)\n",
    "    print(f\"{name} has {len(dataset)} trajectories\")\n",
    "    datasets.append(dataset)\n",
    "\n",
    "# concatenate all datasets\n",
    "combined_dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "print(f\"combined_dataset has {len(combined_dataset)} trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max reward:  0.014876080683840477\n",
      "min reward:  -4.3969874261631573e-05\n"
     ]
    }
   ],
   "source": [
    "# loop through the dataset and find the highest and lowest reward\n",
    "max_rtg = -math.inf\n",
    "min_rtg = math.inf\n",
    "for dataset in datasets:\n",
    "    for rtg in dataset.rtg:\n",
    "        max_rtg = max(max_rtg, rtg.max())\n",
    "        min_rtg = min(min_rtg, rtg.min())\n",
    "\n",
    "\n",
    "print(\"max reward: \", max_rtg)\n",
    "print(\"min reward: \", min_rtg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "batch_size = 32\n",
    "# small learning rate to try to avoid mixed precision caused NaNs\n",
    "lr = 3e-5\n",
    "wt_decay = 1e-4\n",
    "warmup_steps = 10000\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(datasets[0], batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, actions, rtg, timestep, traj_mask = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from the concatenated dataset\n",
    "dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state type:  torch.float64\n",
      "actions type:  torch.float64\n",
      "rtg type:  torch.float64\n",
      "timestep type:  torch.int64\n",
      "traj_mask type:  torch.int64\n"
     ]
    }
   ],
   "source": [
    "# define model parameters\n",
    "# sample 1 batch from dataloader\n",
    "state, actions, rtg, timestep, traj_mask = next(iter(dataloader))\n",
    "# use batch shape to determine state dimension\n",
    "state_dim = state.shape[-1]\n",
    "act_dim = actions.shape[-1] # discrete action space\n",
    "# use batch shape to determine context length\n",
    "\n",
    "# check return tensor type\n",
    "print('state type: ', state.dtype)\n",
    "print('actions type: ', actions.dtype)\n",
    "print('rtg type: ', rtg.dtype)\n",
    "print('timestep type: ', timestep.dtype)\n",
    "print('traj_mask type: ', traj_mask.dtype)\n",
    "\n",
    "\n",
    "n_blocks = 4 # number of transformer blocks\n",
    "h_dim = 96 # hidden dimension\n",
    "n_heads = 8 # number of heads in multi-head attention\n",
    "drop_p = 0.1 # dropout probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = DecisionTransformer(state_dim, act_dim, n_blocks, h_dim, context_len, n_heads, drop_p).to(device)\n",
    "\n",
    "# create optimizer\n",
    "# use larger eps to try to avoid mixed precision overflow caused NaNs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wt_decay, eps=1e-6)\n",
    "\n",
    "# create scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, (step + 1) / warmup_steps))\n",
    "\n",
    "# create a GradScaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler(growth_interval=150)\n",
    "min_scale = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 844144\n"
     ]
    }
   ],
   "source": [
    "# get the model parameters size\n",
    "n_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(f\"Number of parameters: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m traj_mask \u001b[39m=\u001b[39m traj_mask\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m action_targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclone(actions)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m return_preds, state_preds, act_preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(norm_state, rtg, timestep, actions)\n\u001b[1;32m     13\u001b[0m \u001b[39m# check shape of norm_state\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape norm_state: \u001b[39m\u001b[39m{\u001b[39;00mnorm_state\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/cust_transf.py:123\u001b[0m, in \u001b[0;36mDecisionTransformer.forward\u001b[0;34m(self, state, rtg, timestep, actions)\u001b[0m\n\u001b[1;32m    120\u001b[0m time_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_timestep(timestep)\n\u001b[1;32m    122\u001b[0m \u001b[39m# embedding for the state, reward and actions along with time embedding\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m state_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_state(state) \u001b[39m+\u001b[39m time_emb\n\u001b[1;32m    124\u001b[0m rtg_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_rtg(rtg) \u001b[39m+\u001b[39m time_emb\n\u001b[1;32m    125\u001b[0m act_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_act(actions) \u001b[39m+\u001b[39m time_emb\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "# test run the model\n",
    "with torch.no_grad():\n",
    "    state, actions, rtg, timestep , traj_mask= next(iter(dataloader))\n",
    "    state = norm_state.to(device)\n",
    "    actions = actions.to(device)\n",
    "    # convert rtg to float\n",
    "    rtg = rtg.to(device).float()\n",
    "    timestep = timestep.to(device)\n",
    "    traj_mask = traj_mask.to(device)\n",
    "    action_targets = torch.clone(actions).detach().to(device)\n",
    "    return_preds, state_preds, act_preds = model.forward(state, rtg, timestep, actions)\n",
    "\n",
    "    # check shape of norm_state\n",
    "    print(f\"shape norm_state: {tate.shape}\")\n",
    "    # check shape of rtg\n",
    "    print(f\"shape rtg: {rtg.shape}\")\n",
    "    # check shape of timestep\n",
    "    print(f\"shape timestep: {timestep.shape}\")\n",
    "    # check shape of actions\n",
    "    print(f\"shape actions: {actions.shape}\")\n",
    "    print(f\"shape act_preds: {act_preds.shape}\")\n",
    "    print(f\"shape action_targets: {action_targets.shape}\")\n",
    "    \n",
    "    # consider only the action that are padded\n",
    "    act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "    action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "    # check shape of action targets\n",
    "    print(action_targets.shape)\n",
    "    # check shape of action predictions\n",
    "    print(act_preds.shape)\n",
    "\n",
    "# check for nan values and inf values in the input and the output of the model\n",
    "print(torch.isnan(state).any())\n",
    "print(torch.isnan(rtg).any())\n",
    "print(torch.isnan(timestep).any())\n",
    "print(torch.isnan(actions).any())\n",
    "print(torch.isnan(act_preds).any())\n",
    "print(torch.isnan(action_targets).any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# get the start time to calculate training time\n",
    "import datetime\n",
    "\n",
    "# custom training function which take in the model, dataset, optimizer, scheduler, scaler, n_epochs, min_scale\n",
    "def train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale):\n",
    "\n",
    "    # record the start time\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # define training parameters\n",
    "    log_action_losses = []\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "\n",
    "        for norm_state, actions, rtg, timestep, traj_mask in tqdm(dataloader):\n",
    "            # get batch data to device\n",
    "            norm_state = norm_state.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rtg = rtg.to(device).float()\n",
    "            timestep = timestep.to(device)\n",
    "            traj_mask = traj_mask.to(device)\n",
    "\n",
    "            action_targets = torch.clone(actions).detach().to(device)\n",
    "\n",
    "            # Zeroes out the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run forward pass with autocasting\n",
    "            # disable autocasting for now to avoid mixed precision caused NaNs\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                _, _, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "                # consider only the action that are padded\n",
    "                act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "                action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "                # calculate losses just for actions\n",
    "                loss = F.mse_loss(act_preds, action_targets, reduction='mean')\n",
    "\n",
    "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # unscale the gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            # Clips the gradients by norm\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Updates the learning rate according to the scheduler\n",
    "            scheduler.step()\n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            # enforce min scale to avoid mixed precision caused NaNs\n",
    "            if scaler.get_scale() < min_scale:\n",
    "                scaler._scale = torch.tensor(min_scale).to(scaler._scale)\n",
    "        \n",
    "            # append action loss to log\n",
    "            log_action_losses.append(loss.detach().cpu().item())\n",
    "\n",
    "        # print every 10 loss log\n",
    "        if epoch % 100 == 0 or epoch == n_epochs - 1:\n",
    "            print(f'Epoch {epoch}: Loss: {log_action_losses[-1]}')\n",
    "\n",
    "    # record the end time\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f'Training time: {end_time - start_time}')\n",
    "    \n",
    "    return model, log_action_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.587468147277832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 67.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 62.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.32it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.67it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 60.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.85it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.52it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.00it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.36it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 71.56it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.80it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.45it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 72.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 71.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 61.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 61.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 60.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.12it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.85it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss: 0.13367286324501038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 67.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 63.27it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.18it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.89it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.28it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.32it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.77it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.51it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.52it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.24it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.36it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.04it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.81it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 71.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss: 0.2000335305929184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 81.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.89it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.36it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.27it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.56it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.81it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.15it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.77it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.50it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.67it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.98it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.78it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.67it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.15it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.77it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.78it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 89.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.56it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.98it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.89it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Loss: 0.1423427313566208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 82.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.00it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.86it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.51it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.22it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 76.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.86it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.04it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.80it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.18it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.28it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.87it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.52it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.18it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: Loss: 0.2025459110736847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 81.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.81it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.41it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.24it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.85it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.80it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.27it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 75.51it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.39it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.87it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.78it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.86it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.87it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.22it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: Loss: 0.19449269771575928\n",
      "Training time: 0:09:55.818934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train model on each dataloader and store log_action_losses in a list\n",
    "_, log_action_losses = train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save model using torch.save() and save it to a directory\n",
    "directory = 'model'\n",
    "model_name = 'AAPL_model.pt'\n",
    "if not os.path.exists(directory):\n",
    "     os.makedirs(directory)\n",
    "torch.save(model.state_dict(), os.path.join(directory, model_name))\n",
    "\n",
    "# write model parameters to a json file\n",
    "\n",
    "model_params = {\n",
    "     'state_dim': state_dim,\n",
    "     'act_dim': act_dim,\n",
    "     'n_blocks': n_blocks,\n",
    "     'h_dim': h_dim,\n",
    "     'context_len': context_len,\n",
    "     'n_heads': n_heads,\n",
    "     'drop_p': drop_p,\n",
    "}\n",
    "with open(os.path.join(directory, 'AAPL_model_params.json'), 'w') as f:\n",
    "     json.dump(model_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
