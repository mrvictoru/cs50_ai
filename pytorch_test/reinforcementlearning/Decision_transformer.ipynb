{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# this notebook will use a basic GPT based decision transformer in offline reinforcement learning setting to create bot for trading stock\n",
    "# get cuda device\n",
    "# import libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cust_transf import DecisionTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-27a7716f5eae9a12/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets.load import load_dataset\n",
    "\n",
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "data = load_dataset(\"json\", data_files = full_filenames[3], field = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['train']['state'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.load import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# utility function to compute the discounted cumulative sum of a vector\n",
    "def discount_cumsum(x, gamma):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "    return disc_cumsum\n",
    "\n",
    "# define a custom dataset class which loads the data, modifies the reward to be the discounted cumulative sum and apply trajectory masking\n",
    "class CustomTrajTrainDataset(Dataset):\n",
    "    def __init__(self, file_name, context_len, gamma, rtg_scale):\n",
    "        self.gamma = gamma\n",
    "        self.context_len = context_len\n",
    "\n",
    "        # load the data\n",
    "        # TODO: change the data loading to accomodate inhomoegeneous data (different length of trajectories)\n",
    "        self.data = load_dataset(\"json\", data_files = file_name, field = 'data')['train']\n",
    "        \"\"\"\n",
    "        self.data_state = np.array(data['train']['state'], dtype=np.float32)\n",
    "        self.data_action = np.array(data['train']['action'], dtype=np.float32)\n",
    "        self.rtg = np.array(data['train']['reward'], dtype=np.float32)\n",
    "        \"\"\"\n",
    "        self.rtg = []\n",
    "        min_len = 10**6\n",
    "        states = []\n",
    "        for traj in self.data['state']:\n",
    "            states.append(np.array(traj, dtype=np.float32))\n",
    "            if len(traj) < min_len:\n",
    "                min_len = len(traj)\n",
    "\n",
    "        for reward in self.data['reward']:\n",
    "            self.rtg.append(discount_cumsum(np.array(reward, dtype=np.float32), 1.0)/rtg_scale)\n",
    "\n",
    "        states = np.concatenate(states, axis=0)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "        # calculate min len, the mean and std of the state and rtg for all data\n",
    "        self.stateshape = len(states)\n",
    "        # calculate mean of state and rtg with numpy\n",
    "\n",
    "        #self.state_mean = torch.mean(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        #self.state_std = torch.std(data['train']['state'], dim=(-2,-1), keepdim=True)\n",
    "        #self.norm_state = (self.data_state - self.state_mean) / self.state_std\n",
    "\n",
    "        #self.rtg = np.apply_along_axis(discount_cumsum, 1, self.data['reward'], self.gamma) # type: ignore\n",
    "        #self.rtg = self.rtg / rtg_scale\n",
    "\n",
    "    def get_state_stats(self):\n",
    "        return self.state_mean, self.state_std        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.stateshape\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        state = np.array(self.data['state'][idx])\n",
    "        action = np.array(self.data['action'][idx])\n",
    "        rtg = np.array(self.rtg[idx])\n",
    "\n",
    "        data_len = len(state)\n",
    "        \n",
    "        if data_len > self.context_len:\n",
    "            # sample random start index\n",
    "            start_idx = np.random.randint(0, data_len - self.context_len)\n",
    "            # slice the data and convert to torch\n",
    "            state = torch.from_numpy(state[start_idx:start_idx+self.context_len])\n",
    "            action = torch.from_numpy(action[start_idx:start_idx+self.context_len])\n",
    "            rtg = torch.from_numpy(rtg[start_idx:start_idx+self.context_len])\n",
    "            timesteps = torch.arange(start=start_idx, end=start_idx + self.context_len, step=1)\n",
    "            # trajectory mask\n",
    "            mask = torch.ones(self.context_len, dtype=torch.long)\n",
    "        else:\n",
    "            padding_len = self.context_len - data_len\n",
    "\n",
    "            # pad the data with zeros\n",
    "            state = torch.from_numpy(state)\n",
    "            state = torch.cat([state, torch.zeros((padding_len, *state.shape[1:]))], dim=0)\n",
    "\n",
    "            action = torch.from_numpy(action)\n",
    "            action = torch.cat([action, torch.zeros((padding_len, *action.shape[1:]))], dim=0)\n",
    "\n",
    "            rtg = torch.from_numpy(rtg)\n",
    "            rtg = torch.cat([rtg, torch.zeros((padding_len, *rtg.shape[1:]))], dim=0)\n",
    "\n",
    "            timesteps = torch.arange(start=0, end=self.context_len, step=1)\n",
    "\n",
    "            # trajectory mask\n",
    "            mask = torch.cat([torch.ones(data_len, dtype=torch.long), torch.zeros(padding_len, dtype=torch.long)], dim=0)\n",
    "        \n",
    "        return state, action, rtg, timesteps, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-b92f90190ec4f8ad/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1159.93it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-c1a820023dacf4a9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1183.49it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-335e91cc2e824a43/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1032.83it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-27a7716f5eae9a12/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 868.39it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-4c76c05d1d4da50b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 991.56it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-b65de3c8e94feaf3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 878.02it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-0621476d8e1932dc/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1235.80it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-83c863de92176aac/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 966.88it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-097974dd69874e12/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1036.91it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-6f379afa501c4ff4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 803.97it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-e28a3dbe5085cf80/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1171.59it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-7665a45c257a5c6e/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1026.51it/s]\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-2bdf3e25be4d8ee8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1282.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# load huggingface dataset from json file in replaybuffer folder\n",
    "foldername = 'replaybuffer'\n",
    "\n",
    "# get filenames in folder\n",
    "import os\n",
    "filenames = os.listdir(foldername)\n",
    "\n",
    "# get full path of files\n",
    "full_filenames = [os.path.join(foldername, filename) for filename in filenames]\n",
    "\n",
    "# create datasets and store in list from the list of filenames \n",
    "context_len = 30\n",
    "Max_balance = 2147483647\n",
    "gamma = 0.99\n",
    "\n",
    "datasets = []\n",
    "for name in full_filenames:\n",
    "    dataset = CustomTrajTrainDataset(name, context_len, gamma, Max_balance)\n",
    "    datasets.append(dataset)\n",
    "\n",
    "# concatenate all datasets\n",
    "combined_dataset = torch.utils.data.ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12477164e-06],\n",
       "       [1.11948305e-06],\n",
       "       [1.10898952e-06],\n",
       "       [1.09364692e-06],\n",
       "       [1.07318829e-06],\n",
       "       [1.04726178e-06],\n",
       "       [1.01497267e-06],\n",
       "       [9.77262176e-07],\n",
       "       [9.35211063e-07],\n",
       "       [8.87489762e-07],\n",
       "       [8.34665173e-07],\n",
       "       [7.78111826e-07],\n",
       "       [7.16890043e-07],\n",
       "       [6.48865467e-07],\n",
       "       [5.75051331e-07],\n",
       "       [4.93915820e-07],\n",
       "       [4.06925295e-07],\n",
       "       [3.14399813e-07],\n",
       "       [2.19857370e-07],\n",
       "       [1.14428488e-07]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rtg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max reward:  0.021209774548751198\n",
      "min reward:  -2.6889867411926037e-07\n"
     ]
    }
   ],
   "source": [
    "# loop through the dataset and find the highest and lowest reward\n",
    "max_reward = -math.inf\n",
    "min_reward = math.inf\n",
    "for dataset in datasets:\n",
    "    for rtg in dataset.rtg:\n",
    "        max_reward = max(max_reward, rtg.max())\n",
    "        min_reward = min(min_reward, rtg.min())\n",
    "\n",
    "\n",
    "print(\"max reward: \", max_reward)\n",
    "print(\"min reward: \", min_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "batch_size = 32\n",
    "# small learning rate to try to avoid mixed precision caused NaNs\n",
    "lr = 3e-5\n",
    "wt_decay = 1e-4\n",
    "warmup_steps = 10000\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from the concatenated dataset\n",
    "dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "# sample 1 batch from dataloader\n",
    "norm_state, actions, rtg, timestep, traj_mask = next(iter(dataloader))\n",
    "# use batch shape to determine state dimension\n",
    "state_dim = norm_state.shape[-1]\n",
    "act_dim = actions.shape[-1] # discrete action space\n",
    "# use batch shape to determine context length\n",
    "\n",
    "\n",
    "n_blocks = 4 # number of transformer blocks\n",
    "h_dim = 96 # hidden dimension\n",
    "n_heads = 8 # number of heads in multi-head attention\n",
    "drop_p = 0.1 # dropout probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = DecisionTransformer(state_dim, act_dim, n_blocks, h_dim, context_len, n_heads, drop_p).to(device)\n",
    "\n",
    "# create optimizer\n",
    "# use larger eps to try to avoid mixed precision overflow caused NaNs\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wt_decay, eps=1e-6)\n",
    "\n",
    "# create scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(1.0, (step + 1) / warmup_steps))\n",
    "\n",
    "# create a GradScaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler(growth_interval=150)\n",
    "min_scale = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 844144\n"
     ]
    }
   ],
   "source": [
    "# get the model parameters size\n",
    "n_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(f\"Number of parameters: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape norm_state: torch.Size([32, 20, 13])\n",
      "shape rtg: torch.Size([32, 20, 1])\n",
      "shape timestep: torch.Size([32, 20])\n",
      "shape actions: torch.Size([32, 20, 2])\n",
      "shape act_preds: torch.Size([32, 20, 2])\n",
      "shape action_targets: torch.Size([32, 20, 2])\n",
      "torch.Size([640, 2])\n",
      "torch.Size([640, 2])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test run the model\n",
    "with torch.no_grad():\n",
    "    norm_state, actions, rtg, timestep , traj_mask= next(iter(dataloader))\n",
    "    norm_state = norm_state.to(device)\n",
    "    actions = actions.to(device)\n",
    "    # convert rtg to float\n",
    "    rtg = rtg.to(device).float()\n",
    "    timestep = timestep.to(device)\n",
    "    traj_mask = traj_mask.to(device)\n",
    "    action_targets = torch.clone(actions).detach().to(device)\n",
    "    return_preds, state_preds, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "    # check shape of norm_state\n",
    "    print(f\"shape norm_state: {norm_state.shape}\")\n",
    "    # check shape of rtg\n",
    "    print(f\"shape rtg: {rtg.shape}\")\n",
    "    # check shape of timestep\n",
    "    print(f\"shape timestep: {timestep.shape}\")\n",
    "    # check shape of actions\n",
    "    print(f\"shape actions: {actions.shape}\")\n",
    "    print(f\"shape act_preds: {act_preds.shape}\")\n",
    "    print(f\"shape action_targets: {action_targets.shape}\")\n",
    "    \n",
    "    # consider only the action that are padded\n",
    "    act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "    action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "    # check shape of action targets\n",
    "    print(action_targets.shape)\n",
    "    # check shape of action predictions\n",
    "    print(act_preds.shape)\n",
    "\n",
    "# check for nan values and inf values in the input and the output of the model\n",
    "print(torch.isnan(norm_state).any())\n",
    "print(torch.isnan(rtg).any())\n",
    "print(torch.isnan(timestep).any())\n",
    "print(torch.isnan(actions).any())\n",
    "print(torch.isnan(act_preds).any())\n",
    "print(torch.isnan(action_targets).any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# get the start time to calculate training time\n",
    "import datetime\n",
    "\n",
    "# custom training function which take in the model, dataset, optimizer, scheduler, scaler, n_epochs, min_scale\n",
    "def train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale):\n",
    "\n",
    "    # record the start time\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # define training parameters\n",
    "    log_action_losses = []\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "\n",
    "        for norm_state, actions, rtg, timestep, traj_mask in tqdm(dataloader):\n",
    "            # get batch data to device\n",
    "            norm_state = norm_state.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rtg = rtg.to(device).float()\n",
    "            timestep = timestep.to(device)\n",
    "            traj_mask = traj_mask.to(device)\n",
    "\n",
    "            action_targets = torch.clone(actions).detach().to(device)\n",
    "\n",
    "            # Zeroes out the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run forward pass with autocasting\n",
    "            # disable autocasting for now to avoid mixed precision caused NaNs\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                _, _, act_preds = model.forward(norm_state, rtg, timestep, actions)\n",
    "\n",
    "                # consider only the action that are padded\n",
    "                act_preds = act_preds.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "                action_targets = action_targets.view(-1, act_dim)[traj_mask.view(-1) > 0]\n",
    "\n",
    "                # calculate losses just for actions\n",
    "                loss = F.mse_loss(act_preds, action_targets, reduction='mean')\n",
    "\n",
    "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # unscale the gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            # Clips the gradients by norm\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Updates the learning rate according to the scheduler\n",
    "            scheduler.step()\n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            # enforce min scale to avoid mixed precision caused NaNs\n",
    "            if scaler.get_scale() < min_scale:\n",
    "                scaler._scale = torch.tensor(min_scale).to(scaler._scale)\n",
    "        \n",
    "            # append action loss to log\n",
    "            log_action_losses.append(loss.detach().cpu().item())\n",
    "\n",
    "        # print every 10 loss log\n",
    "        if epoch % 100 == 0 or epoch == n_epochs - 1:\n",
    "            print(f'Epoch {epoch}: Loss: {log_action_losses[-1]}')\n",
    "\n",
    "    # record the end time\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f'Training time: {end_time - start_time}')\n",
    "    \n",
    "    return model, log_action_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.587468147277832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 67.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 62.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.32it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.67it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 60.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.85it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.52it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.00it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.36it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 71.56it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.80it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.45it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 72.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 71.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 61.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 61.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 60.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.12it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 70.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.85it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss: 0.13367286324501038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 67.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 63.27it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.18it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.89it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.28it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.32it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.77it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.51it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.52it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.24it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.36it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 68.04it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 65.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 64.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.81it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 67.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 66.47it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 71.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.49it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss: 0.2000335305929184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 81.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.89it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.36it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.27it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.56it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.81it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.15it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.77it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.50it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.67it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.11it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.16it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.06it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.98it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.78it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.67it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.15it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.77it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.07it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.84it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.78it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 89.73it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.56it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.98it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.89it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Loss: 0.1423427313566208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 82.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.00it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 87.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.86it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 88.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.51it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.62it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.22it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 76.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.68it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.99it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 78.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.55it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.86it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.04it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.09it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.80it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.18it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.72it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.44it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.19it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.96it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.28it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.91it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.59it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.87it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.52it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.18it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.71it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.58it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.83it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.23it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.38it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: Loss: 0.2025459110736847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 81.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.81it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.20it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.76it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.48it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.54it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.21it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.35it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.10it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.08it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.41it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.03it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.79it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.24it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.88it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.31it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.85it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.80it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.53it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.46it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.69it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.61it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.17it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.05it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.66it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.27it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.60it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 75.51it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.64it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.39it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 80.14it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.75it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 79.33it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.82it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.92it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.57it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.74it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 81.87it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.65it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.78it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.63it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.34it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.30it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.86it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.95it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.93it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.87it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.26it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 82.90it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.25it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.37it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.97it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.01it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.22it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.43it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.29it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 83.70it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 85.40it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 86.02it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.13it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.42it/s]\n",
      "100%|██████████| 91/91 [00:01<00:00, 84.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: Loss: 0.19449269771575928\n",
      "Training time: 0:09:55.818934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train model on each dataloader and store log_action_losses in a list\n",
    "_, log_action_losses = train_model(model, dataloader, optimizer, scheduler, scaler, n_epochs, min_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save model using torch.save() and save it to a directory\n",
    "directory = 'model'\n",
    "model_name = 'AAPL_model.pt'\n",
    "if not os.path.exists(directory):\n",
    "     os.makedirs(directory)\n",
    "torch.save(model.state_dict(), os.path.join(directory, model_name))\n",
    "\n",
    "# write model parameters to a json file\n",
    "\n",
    "model_params = {\n",
    "     'state_dim': state_dim,\n",
    "     'act_dim': act_dim,\n",
    "     'n_blocks': n_blocks,\n",
    "     'h_dim': h_dim,\n",
    "     'context_len': context_len,\n",
    "     'n_heads': n_heads,\n",
    "     'drop_p': drop_p,\n",
    "}\n",
    "with open(os.path.join(directory, 'AAPL_model_params.json'), 'w') as f:\n",
    "     json.dump(model_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
