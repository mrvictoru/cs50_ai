{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook will use a basic GPT based decision transformer in offline reinforcement learning setting to create bot for trading stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# based on https://github.com/nikhilbarhate99/min-decision-transformer/blob/master/decision_transformer/model.py\n",
    "\n",
    "# define the masked causal attention\n",
    "class MaskedAttention(nn.Module):\n",
    "    def __init__(self, h_dim, max_T, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.drop_p = drop_p\n",
    "        # feed forward networks which create the query, key and value\n",
    "        self.Q_net = nn.Linear(h_dim, h_dim)\n",
    "        self.K_net = nn.Linear(h_dim, h_dim)\n",
    "        self.V_net = nn.Linear(h_dim, h_dim)\n",
    "\n",
    "        # feed forward network which projects the attention to the correct dimension\n",
    "        self.proj_net = nn.Linear(h_dim, h_dim)\n",
    "\n",
    "        # dropout layers\n",
    "        self.att_drop = nn.Dropout(drop_p)\n",
    "        self.proj_drop = nn.Dropout(drop_p)\n",
    "\n",
    "        # create the mask\n",
    "        mask = torch.tril(torch.ones(max_T, max_T)).view(1, 1, max_T, max_T)\n",
    "\n",
    "        # register_buffer will make the mask a constant tensor\n",
    "        # so that it will not be included in the model parameters and be updated during backpropagation\n",
    "        self.register_buffer('mask', mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, H]\n",
    "        B, T, C = x.shape # batch size, sequence length, hidden dimension * number of heads\n",
    "        N, D = self.n_heads, C // self.n_heads # number of heads, dimension of each head\n",
    "\n",
    "        # compute the query, key and value\n",
    "        Q = self.Q_net(x).view(B, T, N, D).transpose(1, 2) # [B, N, T, D]\n",
    "        K = self.K_net(x).view(B, T, N, D).transpose(1, 2)\n",
    "        V = self.V_net(x).view(B, T, N, D).transpose(1, 2)\n",
    "\n",
    "        # compute the attention\n",
    "        weights = Q @ K.transpose(2,3) / math.sqrt(D) # QK^T / sqrt(D)\n",
    "        weights = weights.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf')) # mask the future tokens\n",
    "        normalized_weights = F.softmax(weights, dim=-1) # softmax along the last dimension\n",
    "        A = self.att_drop(normalized_weights) # attention with dropout\n",
    "\n",
    "        # compute the output\n",
    "        # gather heads and project to correct dimension\n",
    "        attention = A.transpose(1, 2).contiguous().view(B, T, N*D)\n",
    "        out = self.proj_drop(self.proj_net(attention))\n",
    "\n",
    "        return out\n",
    "\n",
    "# define the attention block with layer normalization and residual connection as well as the feed forward network\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, h_dim, max_T, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "        self.attention = MaskedAttention(h_dim, max_T, n_heads, drop_p)\n",
    "        self.norm1 = nn.LayerNorm(h_dim)\n",
    "        self.norm2 = nn.LayerNorm(h_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(h_dim, 4*h_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*h_dim, h_dim),\n",
    "            nn.Dropout(drop_p)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, H]\n",
    "        # Attention -> LayerNorm -> Residual -> FFN -> LayerNorm -> Residual\n",
    "        out = self.norm1(x + self.attention(x))\n",
    "        out = self.norm2(out + self.ffn(out))\n",
    "\n",
    "        return out\n",
    "\n",
    "# define the decision transformer\n",
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(self, state_dim, act_dim, n_block, h_dim, context_len, n_heads, drop_p, max_timestep = 4096):\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.h_dim = h_dim\n",
    "\n",
    "        # transformer blocks\n",
    "        input_seq_len = 3 * context_len\n",
    "        blocks = [AttentionBlock(h_dim, input_seq_len, n_heads, drop_p) for _ in range(n_block)]\n",
    "        self.transformer = nn.Sequential(*blocks)\n",
    "\n",
    "        # projection heads (project to embedding)\n",
    "        self.embed_ln = nn.LayerNorm(h_dim)\n",
    "        self.embed_timestep = nn.Embedding(max_timestep, h_dim)\n",
    "        self.embed_rtg = nn.Linear(1, h_dim)\n",
    "        self.embed_state = nn.Linear(state_dim, h_dim)\n",
    "\n",
    "        # discrete actions\n",
    "        self.embed_act = torch.nn.Embedding(act_dim+1, h_dim)\n",
    "        use_action_tah = False # for discrete action\n",
    "\n",
    "        # prediction heads\n",
    "        self.pred_rtg = nn.Linear(h_dim, 1)\n",
    "        self.pred_state = nn.Linear(h_dim, state_dim)\n",
    "        self.pred_act = nn.Sequential(*([nn.Linear(h_dim, act_dim)] + ([nn.Tanh()] if use_action_tah else [])))\n",
    "    \n",
    "    def forward(self, state, rtg, timestep, actions):\n",
    "        B, T, _ = state.shape\n",
    "\n",
    "        # timestep embedding\n",
    "        time_emb = self.embed_timestep(timestep)\n",
    "\n",
    "        # embedding for the state, reward and actions along with time embedding\n",
    "        state_emb = self.embed_state(state) + time_emb\n",
    "        rtg_emb = self.embed_rtg(rtg) + time_emb\n",
    "        act_emb = torch.squeeze(self.embed_act(actions))\n",
    "        act_emb = act_emb + time_emb\n",
    "\n",
    "        # stack the embeddings and reshape sequence as (r1, s1, a1, r2, s2, a2, ...)\n",
    "        h = torch.stack([rtg_emb, state_emb, act_emb], dim=1).permute(0,2,1,3).reshape(B, 3*T, self.h_dim)\n",
    "        h = self.embed_ln(h)\n",
    "\n",
    "        # transformer blocks\n",
    "        h = self.transformer(h)\n",
    "\n",
    "        # get h reshaped such that its size is (B, 3, T, h_dim) and\n",
    "        # h[:, 0, t] is conditioned on r_0, s_0, a_0, ..., r_t\n",
    "        # h[:, 1, t] is conditioned on r_0, s_0, a_0, ..., r_t, s_t\n",
    "        # h[:, 2, t] is conditioned on r_0, s_0, a_0, ..., r_t, s_t, a_t\n",
    "        h = h.reshape(B, 3, T, self.h_dim).permute(0,2,1,3)\n",
    "\n",
    "        # get predictions\n",
    "        return_preds = self.pred_rtg(h[:,2])    # predict next rtg given r, s, a\n",
    "        state_preds = self.pred_state(h[:,2])   # predict next state given r, s, a\n",
    "        act_preds = self.pred_act(h[:,2])       # predict action given r, s\n",
    "\n",
    "        return return_preds, state_preds, act_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7b412463aad4e1b3\n",
      "Found cached dataset json (/home/victoru/.cache/huggingface/datasets/json/default-7b412463aad4e1b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 752.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# load huggingface dataset from json file\n",
    "filename = 'AAPL_replaybuffer.json'\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=filename, field='data').with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cuda device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# define training parameters\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "wt_decay = 1e-4\n",
    "warmup_steps = 10000\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from dataset\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset['train'], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "# sample 1 batch from dataloader\n",
    "batch = next(iter(dataloader))\n",
    "# use batch shape to determine state dimension\n",
    "state_dim = batch['state'].shape[-1]\n",
    "act_dim = batch['action'].shape[-1] # discrete action space\n",
    "# use batch shape to determine context length\n",
    "context_len = batch['timestep'].shape[-1] # K in decision transformer\n",
    "\n",
    "n_blocks = 6 # number of transformer blocks\n",
    "h_dim = 128 # hidden dimension\n",
    "n_heads = 2 # number of heads in multi-head attention\n",
    "drop_p = 0.1 # dropout probability\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = DecisionTransformer(state_dim, act_dim, n_blocks, h_dim, context_len, n_heads, drop_p).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 84, 128]' is invalid for input of size 56448",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m rtgs \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mreward\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m actions \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39maction\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m state_preds, rtg_preds, act_preds \u001b[39m=\u001b[39m model(states, rtgs, timesteps, actions)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb Cell 8\u001b[0m in \u001b[0;36mDecisionTransformer.forward\u001b[0;34m(self, state, rtg, timestep, actions)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_ln(h)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# transformer blocks\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(h)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m# get h reshaped such that its size is (B, 3, T, h_dim) and\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39m# h[:, 0, t] is conditioned on r_0, s_0, a_0, ..., r_t\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39m# h[:, 1, t] is conditioned on r_0, s_0, a_0, ..., r_t, s_t\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m# h[:, 2, t] is conditioned on r_0, s_0, a_0, ..., r_t, s_t, a_t\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m h \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mreshape(B, \u001b[39m3\u001b[39m, T, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh_dim)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb Cell 8\u001b[0m in \u001b[0;36mAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39m# x: [B, T, H]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39m# Attention -> LayerNorm -> Residual -> FFN -> LayerNorm -> Residual\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mffn(out))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/testpython/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb Cell 8\u001b[0m in \u001b[0;36mMaskedAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matt_drop(normalized_weights) \u001b[39m# attention with dropout\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# compute the output\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# gather heads and project to correct dimension\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m attention \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39;49mview(B, T, N\u001b[39m*\u001b[39;49mD)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_drop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_net(attention))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/victoru/B612CEC512CE8A37/ai50/pytorch_test/reinforcementlearning/Decision_transformer.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 84, 128]' is invalid for input of size 56448"
     ]
    }
   ],
   "source": [
    "# test run of the model\n",
    "for batch in dataloader:\n",
    "    timesteps = batch['timestep'].to(device)\n",
    "\n",
    "    states = batch['state'].to(device)\n",
    "\n",
    "    rtgs = batch['reward'].to(device)\n",
    "\n",
    "    actions = batch['action'].to(device)\n",
    "\n",
    "    state_preds, rtg_preds, act_preds = model(states, rtgs, timesteps, actions)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test act_embedding\n",
    "embed_act = nn.Embedding(act_dim+1, h_dim)\n",
    "embed_timestep = nn.Embedding(4096, h_dim)\n",
    "embed_rtg = nn.Linear(1, h_dim)\n",
    "embed_state = nn.Linear(state_dim, h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "actions = batch['action']\n",
    "timesteps = batch['timestep']\n",
    "reward = batch['reward']\n",
    "states = batch['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 1])\n",
      "torch.Size([4, 28, 1])\n",
      "torch.Size([4, 28])\n",
      "torch.Size([4, 28, 5])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([4096, 128])\n",
      "torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "print(actions.shape)\n",
    "print(reward.shape)\n",
    "print(timesteps.shape)\n",
    "print(states.shape)\n",
    "print(embed_act.weight.shape)\n",
    "print(embed_rtg.weight.shape)\n",
    "print(embed_timestep.weight.shape)\n",
    "print(embed_state.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 128])\n"
     ]
    }
   ],
   "source": [
    "time_emb = embed_timestep(timesteps)\n",
    "print(time_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_state(states).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_emb = embed_state(states) + time_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_emb = embed_rtg(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_emb = torch.squeeze(embed_act(actions))\n",
    "act_emb = act_emb + time_emb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testpython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
