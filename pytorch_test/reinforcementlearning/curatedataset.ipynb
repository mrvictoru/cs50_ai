{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is for creating and testing method on curating datasets on stock trading data for offline reinforcement learning with decision transformer model\n",
    "# This will get stock data from yahoo finance\n",
    "# Then it will use the stock data to create gym environments and sample state, action, reward (both randomly or/and by a trained agent ) which then store as a replay buffer\n",
    "# Group these replay buffers and export as a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    }
   ],
   "source": [
    "# import helper function for getting stock data\n",
    "from getstock import get_stock_data_yf_between_with_indicators\n",
    "# import time library\n",
    "from datetime import datetime, timedelta\n",
    "# get stock data with technical indicators\n",
    "stock_name = 'AAPL'\n",
    "\n",
    "# period of data to get\n",
    "period = 365*6\n",
    "# start_date in format 'YYYY-MM-DD'\n",
    "start_date = '2016-01-01'\n",
    "# calculate end date being x days after start date\n",
    "start_date_obj = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_obj = start_date_obj + timedelta(days=period)\n",
    "end_date = end_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "interval = '1d'\n",
    "indicators = ['volume_obv', 'trend_macd', 'momentum_rsi']\n",
    "\n",
    "stockdata = get_stock_data_yf_between_with_indicators(stock_name, start_date, end_date, interval, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>momentum_rsi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>26.752501</td>\n",
       "      <td>26.757500</td>\n",
       "      <td>26.205000</td>\n",
       "      <td>26.315001</td>\n",
       "      <td>163649200</td>\n",
       "      <td>163649200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>25.652500</td>\n",
       "      <td>26.342501</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>26.337500</td>\n",
       "      <td>270597600</td>\n",
       "      <td>434246800</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>26.437500</td>\n",
       "      <td>26.462500</td>\n",
       "      <td>25.602501</td>\n",
       "      <td>25.677500</td>\n",
       "      <td>223164000</td>\n",
       "      <td>211082800</td>\n",
       "      <td>-0.049469</td>\n",
       "      <td>3.068330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>25.139999</td>\n",
       "      <td>25.592501</td>\n",
       "      <td>24.967501</td>\n",
       "      <td>25.174999</td>\n",
       "      <td>273829600</td>\n",
       "      <td>-62746800</td>\n",
       "      <td>-0.129155</td>\n",
       "      <td>1.709592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>24.670000</td>\n",
       "      <td>25.032499</td>\n",
       "      <td>24.107500</td>\n",
       "      <td>24.112499</td>\n",
       "      <td>324377600</td>\n",
       "      <td>-387124400</td>\n",
       "      <td>-0.274873</td>\n",
       "      <td>0.851243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-06</th>\n",
       "      <td>34.842499</td>\n",
       "      <td>34.942501</td>\n",
       "      <td>34.650002</td>\n",
       "      <td>34.834999</td>\n",
       "      <td>87000000</td>\n",
       "      <td>3318554400</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>80.861505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-07</th>\n",
       "      <td>34.764999</td>\n",
       "      <td>34.994999</td>\n",
       "      <td>34.697498</td>\n",
       "      <td>34.880001</td>\n",
       "      <td>69785200</td>\n",
       "      <td>3388339600</td>\n",
       "      <td>0.943343</td>\n",
       "      <td>81.196406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-08</th>\n",
       "      <td>34.737499</td>\n",
       "      <td>34.950001</td>\n",
       "      <td>34.705002</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>74828800</td>\n",
       "      <td>3313510800</td>\n",
       "      <td>0.901533</td>\n",
       "      <td>77.004380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-09</th>\n",
       "      <td>34.685001</td>\n",
       "      <td>34.697498</td>\n",
       "      <td>34.262501</td>\n",
       "      <td>34.669998</td>\n",
       "      <td>88623600</td>\n",
       "      <td>3224887200</td>\n",
       "      <td>0.852120</td>\n",
       "      <td>74.456792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-10</th>\n",
       "      <td>34.812500</td>\n",
       "      <td>34.840000</td>\n",
       "      <td>34.660000</td>\n",
       "      <td>34.785000</td>\n",
       "      <td>78451200</td>\n",
       "      <td>3303338400</td>\n",
       "      <td>0.812869</td>\n",
       "      <td>75.701268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close     Volume  volume_obv  \\\n",
       "Date                                                                            \n",
       "2015-12-31  26.752501  26.757500  26.205000  26.315001  163649200   163649200   \n",
       "2016-01-04  25.652500  26.342501  25.500000  26.337500  270597600   434246800   \n",
       "2016-01-05  26.437500  26.462500  25.602501  25.677500  223164000   211082800   \n",
       "2016-01-06  25.139999  25.592501  24.967501  25.174999  273829600   -62746800   \n",
       "2016-01-07  24.670000  25.032499  24.107500  24.112499  324377600  -387124400   \n",
       "...               ...        ...        ...        ...        ...         ...   \n",
       "2017-03-06  34.842499  34.942501  34.650002  34.834999   87000000  3318554400   \n",
       "2017-03-07  34.764999  34.994999  34.697498  34.880001   69785200  3388339600   \n",
       "2017-03-08  34.737499  34.950001  34.705002  34.750000   74828800  3313510800   \n",
       "2017-03-09  34.685001  34.697498  34.262501  34.669998   88623600  3224887200   \n",
       "2017-03-10  34.812500  34.840000  34.660000  34.785000   78451200  3303338400   \n",
       "\n",
       "            trend_macd  momentum_rsi  \n",
       "Date                                  \n",
       "2015-12-31    0.000000    100.000000  \n",
       "2016-01-04    0.001795    100.000000  \n",
       "2016-01-05   -0.049469      3.068330  \n",
       "2016-01-06   -0.129155      1.709592  \n",
       "2016-01-07   -0.274873      0.851243  \n",
       "...                ...           ...  \n",
       "2017-03-06    0.969750     80.861505  \n",
       "2017-03-07    0.943343     81.196406  \n",
       "2017-03-08    0.901533     77.004380  \n",
       "2017-03-09    0.852120     74.456792  \n",
       "2017-03-10    0.812869     75.701268  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockdata.iloc[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float16\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "# create the gym environment using the stock data\n",
    "import gym\n",
    "from TradingEnvClass import StockTradingEnv\n",
    "\n",
    "init_balance = 10000\n",
    "max_step = len(stockdata)-1\n",
    "\n",
    "env = StockTradingEnv(stockdata, init_balance, max_step, random = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoru/anaconda3/envs/testpython/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# create dictionary with state, action, reward as keys and store the values in a list\n",
    "# then create a huggingface dataset from the dictionary\n",
    "# then save the huggingface dataset to a file\n",
    "import numpy as np\n",
    "from datasets import Dataset as huggingfaceDataset\n",
    "\n",
    "data = {'data':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 Timestep:  1509\n",
      "Episode:  1 Timestep:  1509\n",
      "Episode:  2 Timestep:  1509\n",
      "Episode:  3 Timestep:  1509\n",
      "Episode:  4 Timestep:  1509\n",
      "Episode:  5 Timestep:  1509\n",
      "Episode:  6 Timestep:  1509\n",
      "Episode:  7 Timestep:  1509\n",
      "Episode:  8 Timestep:  1509\n",
      "Episode:  9 Timestep:  1509\n",
      "Episode:  10 Timestep:  1509\n",
      "Episode:  11 Timestep:  1509\n",
      "Episode:  12 Timestep:  1509\n",
      "Episode:  13 Timestep:  1509\n",
      "Episode:  14 Timestep:  1509\n",
      "Episode:  15 Timestep:  1509\n",
      "Episode:  16 Timestep:  1509\n",
      "Episode:  17 Timestep:  1509\n",
      "Episode:  18 Timestep:  1509\n",
      "Episode:  19 Timestep:  1509\n",
      "Episode:  20 Timestep:  1509\n",
      "Episode:  21 Timestep:  1509\n",
      "Episode:  22 Timestep:  1509\n",
      "Episode:  23 Timestep:  1509\n",
      "Episode:  24 Timestep:  1509\n",
      "Episode:  25 Timestep:  1509\n",
      "Episode:  26 Timestep:  1509\n",
      "Episode:  27 Timestep:  1509\n",
      "Episode:  28 Timestep:  1509\n",
      "Episode:  29 Timestep:  1509\n",
      "Episode:  30 Timestep:  1509\n",
      "Episode:  31 Timestep:  1509\n",
      "Episode:  32 Timestep:  1509\n",
      "Episode:  33 Timestep:  1509\n",
      "Episode:  34 Timestep:  1509\n",
      "Episode:  35 Timestep:  1509\n",
      "Episode:  36 Timestep:  1509\n",
      "Episode:  37 Timestep:  1509\n",
      "Episode:  38 Timestep:  1509\n",
      "Episode:  39 Timestep:  1509\n",
      "Episode:  40 Timestep:  1509\n",
      "Episode:  41 Timestep:  1509\n",
      "Episode:  42 Timestep:  1509\n",
      "Episode:  43 Timestep:  1509\n",
      "Episode:  44 Timestep:  1509\n",
      "Episode:  45 Timestep:  1509\n",
      "Episode:  46 Timestep:  1509\n",
      "Episode:  47 Timestep:  1509\n",
      "Episode:  48 Timestep:  1509\n",
      "Episode:  49 Timestep:  1509\n",
      "Episode:  50 Timestep:  1509\n",
      "Episode:  51 Timestep:  1509\n",
      "Episode:  52 Timestep:  1509\n",
      "Episode:  53 Timestep:  1509\n",
      "Episode:  54 Timestep:  1509\n",
      "Episode:  55 Timestep:  1509\n",
      "Episode:  56 Timestep:  1509\n",
      "Episode:  57 Timestep:  1509\n",
      "Episode:  58 Timestep:  1509\n",
      "Episode:  59 Timestep:  1509\n",
      "Episode:  60 Timestep:  1509\n",
      "Episode:  61 Timestep:  1509\n",
      "Episode:  62 Timestep:  1509\n",
      "Episode:  63 Timestep:  1509\n",
      "Episode:  64 Timestep:  1509\n",
      "Episode:  65 Timestep:  1509\n",
      "Episode:  66 Timestep:  1509\n",
      "Episode:  67 Timestep:  1509\n",
      "Episode:  68 Timestep:  1509\n",
      "Episode:  69 Timestep:  1509\n",
      "Episode:  70 Timestep:  1509\n",
      "Episode:  71 Timestep:  1509\n",
      "Episode:  72 Timestep:  1509\n",
      "Episode:  73 Timestep:  1509\n",
      "Episode:  74 Timestep:  1509\n",
      "Episode:  75 Timestep:  1509\n",
      "Episode:  76 Timestep:  1509\n",
      "Episode:  77 Timestep:  1509\n",
      "Episode:  78 Timestep:  1509\n",
      "Episode:  79 Timestep:  1509\n",
      "Episode:  80 Timestep:  1509\n",
      "Episode:  81 Timestep:  1509\n",
      "Episode:  82 Timestep:  1509\n",
      "Episode:  83 Timestep:  1509\n",
      "Episode:  84 Timestep:  1509\n",
      "Episode:  85 Timestep:  1509\n",
      "Episode:  86 Timestep:  1509\n",
      "Episode:  87 Timestep:  1509\n",
      "Episode:  88 Timestep:  1509\n",
      "Episode:  89 Timestep:  1509\n",
      "Episode:  90 Timestep:  1509\n",
      "Episode:  91 Timestep:  1509\n",
      "Episode:  92 Timestep:  1509\n",
      "Episode:  93 Timestep:  1509\n",
      "Episode:  94 Timestep:  1509\n",
      "Episode:  95 Timestep:  1509\n",
      "Episode:  96 Timestep:  1509\n",
      "Episode:  97 Timestep:  1509\n",
      "Episode:  98 Timestep:  1509\n",
      "Episode:  99 Timestep:  1509\n"
     ]
    }
   ],
   "source": [
    "# create a loop to sample state, action, reward and store in the dictionary\n",
    "num_episodes = 1000\n",
    "for i in range(num_episodes):\n",
    "    # create list for storing state, action, reward\n",
    "    dict = {'state': [], 'action': [], 'reward': [], 'timestep': []}\n",
    "    # reset the environment\n",
    "    state = env.reset()\n",
    "    dict['state'].append(state.tolist())\n",
    "    timestep = 0\n",
    "    done = False\n",
    "    # create a loop to sample action, next_state, reward and store in the dictionary\n",
    "    while not done:\n",
    "        # sample action\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        # store state, action, reward in the dictionary\n",
    "        dict['action'].append(action.tolist())\n",
    "        dict['reward'].append([reward])\n",
    "        dict['timestep'].append(timestep)\n",
    "        # update state\n",
    "        timestep += 1\n",
    "        state = next_state\n",
    "        # check if done\n",
    "        if done:\n",
    "            print('Episode: ', i, 'Timestep: ', timestep)\n",
    "            break\n",
    "        else:\n",
    "            dict['state'].append(state.tolist())\n",
    "    \n",
    "    # store the state, action, reward list in the dictionary\n",
    "    data['data'].append(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = stock_name + '_' + period + '_' + start_date + '_' + interval + '_random_replaybuffer.json'\n",
    "# output the dictionary to a json file\n",
    "import json\n",
    "with open(file_name, 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an agent using stable baselines\n",
    "# import stable baselines \n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.policies import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# create the environment as a vectorized environment for stable baselines training\n",
    "env_stable = DummyVecEnv([lambda: StockTradingEnv(stockdata.iloc[0:400], init_balance, max_step, random = True)])\n",
    "\n",
    "# create the models\n",
    "modelPPO = PPO(MlpPolicy, env_stable, verbose=1)\n",
    "modelA2C = A2C(MlpPolicy, env_stable, verbose=1)\n",
    "modelDDPG = DDPG(MlpPolicy, env_stable, verbose=1)\n",
    "\n",
    "# train the models\n",
    "modelPPO.learn(total_timesteps=10000)\n",
    "modelA2C.learn(total_timesteps=10000)\n",
    "modelDDPG.learn(total_timesteps=10000)\n",
    "\n",
    "# store the models' name in a list\n",
    "model_list = [modelPPO, modelA2C, modelDDPG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models\n",
    "mean_reward, std_reward = evaluate_policy(modelPPO, env_stable, n_eval_episodes=10)\n",
    "mean_reward2, std_reward2 = evaluate_policy(modelA2C, env_stable, n_eval_episodes=10)\n",
    "mean_reward3, std_reward3 = evaluate_policy(modelDDPG, env_stable, n_eval_episodes=10)\n",
    "\n",
    "print('PPO mean reward: ', mean_reward, 'std reward: ', std_reward)\n",
    "print('A2C mean reward: ', mean_reward2, 'std reward: ', std_reward2)\n",
    "print('DDPG mean reward: ', mean_reward3, 'std reward: ', std_reward3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: create a loop to sample state, action from the each models, reward and store in the dictionary\n",
    "output = []\n",
    "num_episodes = 500\n",
    "# loop through the models\n",
    "for model in model_list:\n",
    "    data2 = {'data':[]}\n",
    "    for i in range(num_episodes):\n",
    "        # create list for storing state, action, reward\n",
    "        dict = {'state': [], 'action': [], 'reward': [], 'timestep': []}\n",
    "        # reset the environment\n",
    "        state = env.reset()\n",
    "        dict['state'].append(state.tolist())\n",
    "        timestep = 0\n",
    "        done = False\n",
    "        # create a loop to sample action, next_state, reward and store in the dictionary\n",
    "        while not done:\n",
    "            # sample action\n",
    "            action, _states = model.predict(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            # store state, action, reward in the dictionary\n",
    "            dict['action'].append(action.tolist())\n",
    "            dict['reward'].append([reward])\n",
    "            dict['timestep'].append(timestep)\n",
    "            # update state\n",
    "            timestep += 1\n",
    "            state = next_state\n",
    "            # check if done\n",
    "            if done:\n",
    "                print('Episode: ', i, 'Timestep: ', timestep)\n",
    "                break\n",
    "            else:\n",
    "                dict['state'].append(state.tolist())\n",
    "        \n",
    "        # store the state, action, reward list in the dictionary\n",
    "    data2['data'].append(dict)\n",
    "    output.append(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the output list and save each dictionary to a json file\n",
    "for i in range(len(output)):\n",
    "    file_name = stock_name + '_' + period + '_' + start_date + '_' + interval + '_' + model_list[i].__class__.__name__ + '_replaybuffer.json'\n",
    "    # output the dictionary to a json file\n",
    "    import json\n",
    "    with open(file_name, 'w') as fp:\n",
    "        json.dump(output[i], fp)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d1dcbd6682217e1a7c0b1a7c0c54c0b39a029f0fde86a6625ffa444d0c385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
